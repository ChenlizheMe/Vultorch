{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Vultorch Tutorial","text":"<p>A step-by-step guide through Vultorch, one example at a time. Each chapter maps to a runnable script in the <code>examples/</code> folder.</p> Chapter Topic Key concepts 01 \u2014 Hello Tensor Minimal display View, Panel, Canvas, bind, run 02 \u2014 Multi-Panel Multiple panels &amp; canvases Layout, side, multi-canvas 03 \u2014 Training Test Fit a tiny network to a GT image custom dock layout, create_tensor, per-pixel optimization <p>More chapters coming soon.</p>"},{"location":"01_hello_tensor/","title":"01 \u2014 Hello Tensor","text":"<p>Example file: <code>examples/01_hello_tensor.py</code></p> <p>Tired of every research repo inventing its own janky tensor viewer with matplotlib hacks and <code>cv2.imshow</code> spaghetti?  Yeah, us too.</p> <p>Vultorch gets your CUDA tensor on screen in four lines \u2014 no saving PNGs, no CPU round-trips, no <code>plt.pause(0.001)</code> nonsense.</p>"},{"location":"01_hello_tensor/#the-mental-model","title":"The mental model","text":"<p>There are exactly four objects you need to know:</p> Object What it is One-liner View The OS window <code>vultorch.View(\"title\", w, h)</code> Panel A dockable sub-window inside the View <code>view.panel(\"name\")</code> Canvas A GPU image slot inside a Panel <code>panel.canvas(\"name\")</code> bind() Connects a tensor to a Canvas <code>canvas.bind(t)</code> <p>Chain them together, call <code>run()</code>, done.</p>"},{"location":"01_hello_tensor/#full-code","title":"Full code","text":"<pre><code>import torch\nimport vultorch\n\n# A 256\u00d7256 RGB gradient \u2014 any (H,W,C) float32 CUDA tensor works\nH, W = 256, 256\nx = torch.linspace(0, 1, W, device=\"cuda\")\ny = torch.linspace(0, 1, H, device=\"cuda\")\nt = torch.stack([\n    x.unsqueeze(0).expand(H, W),\n    y.unsqueeze(1).expand(H, W),\n    torch.full((H, W), 0.3, device=\"cuda\"),\n], dim=-1)  # (256, 256, 3)\n\nview   = vultorch.View(\"01 - Hello Tensor\", 512, 512)\npanel  = view.panel(\"Viewer\")\ncanvas = panel.canvas(\"gradient\")\ncanvas.bind(t)\nview.run()  # blocks until you close the window\n</code></pre> <p>That's it. No event loop boilerplate, no <code>begin_frame()</code> / <code>end_frame()</code>.</p>"},{"location":"01_hello_tensor/#what-just-happened","title":"What just happened?","text":"<ol> <li> <p>Data \u2014 we made an RGB gradient on CUDA. Vultorch accepts <code>(H,W)</code>,    <code>(H,W,1)</code>, <code>(H,W,3)</code>, or <code>(H,W,4)</code>, in float32 / float16 / uint8.    It handles RGBA expansion for you.</p> </li> <li> <p>Object tree \u2014 <code>View</code> \u2192 <code>Panel</code> \u2192 <code>Canvas</code> \u2192 <code>bind(tensor)</code>.    The canvas auto-fills its panel by default (<code>fit=True</code>).</p> </li> <li> <p>Run \u2014 <code>view.run()</code> enters a blocking event loop. Every frame the    canvas re-uploads the bound tensor and renders it. Close the window    to exit.</p> </li> </ol> <p>Tip</p> <p>The four setup lines collapse into a one-liner if you're feeling fancy: <code>view.panel(\"Viewer\").canvas(\"gradient\").bind(t)</code></p>"},{"location":"02_multi_panel/","title":"02 \u2014 Multi-Panel","text":"<p>Example file: <code>examples/02_imgui_controls.py</code></p> <p>One panel is nice. But in practice you want to see your loss map, gradient field, and output side-by-side \u2014 without writing a single line of layout code.</p> <p>Good news: Vultorch panels are dockable. Just create them and they'll arrange themselves. Users can drag, resize, and rearrange at will.</p> <p>This chapter shows two patterns:</p> <ul> <li>One canvas per panel \u2014 three panels stacked, each with its own tensor.</li> <li>Multiple canvases in one panel \u2014 one panel, three canvases, auto-split.</li> </ul>"},{"location":"02_multi_panel/#layout","title":"Layout","text":"<p>Here's what the window looks like:</p> Left side (main area) Right side (<code>side=\"right\"</code>) Red panel \u2014 <code>red_img</code> Combined panel Green panel \u2014 <code>green_img</code> <code>c_red</code> canvas Blue panel \u2014 <code>blue_img</code> <code>c_green</code> canvas <code>c_blue</code> canvas <p>Left: 3 separate panels, each one canvas. Right: 1 panel, 3 canvases sharing space.</p>"},{"location":"02_multi_panel/#full-code","title":"Full code","text":"<pre><code>import torch\nimport vultorch\n\nH, W = 128, 128\ndevice = \"cuda\"\n\n# Three different tensors\nx = torch.linspace(0, 1, W, device=device)\nred = torch.zeros(H, W, 3, device=device)\nred[:, :, 0] = x.unsqueeze(0).expand(H, W)\n\ny = torch.linspace(0, 1, H, device=device)\ngreen = torch.zeros(H, W, 3, device=device)\ngreen[:, :, 1] = y.unsqueeze(1).expand(H, W)\n\nblue = torch.zeros(H, W, 3, device=device)\ncx = (torch.arange(W, device=device) // 32) % 2\ncy = (torch.arange(H, device=device) // 32) % 2\nblue[:, :, 2] = (cx.unsqueeze(0) ^ cy.unsqueeze(1)).float()\n\nview = vultorch.View(\"02 - Multi-Panel\", 1200, 600)\n\n# Left: 3 panels, each with one canvas\npanel_r = view.panel(\"Red\")\npanel_g = view.panel(\"Green\")\npanel_b = view.panel(\"Blue\")\npanel_r.canvas(\"red_img\").bind(red)\npanel_g.canvas(\"green_img\").bind(green)\npanel_b.canvas(\"blue_img\").bind(blue)\n\n# Right: 1 panel with 3 canvases (auto-split vertically)\ncombined = view.panel(\"Combined\", side=\"right\", width=0.5)\ncombined.canvas(\"c_red\").bind(red)\ncombined.canvas(\"c_green\").bind(green)\ncombined.canvas(\"c_blue\").bind(blue)\n\nview.run()\n</code></pre>"},{"location":"02_multi_panel/#key-takeaways","title":"Key takeaways","text":"<ol> <li> <p>Auto-layout \u2014 panels without <code>side=</code> stack vertically.    Add <code>side=\"right\"</code> (or <code>\"left\"</code>) + <code>width=0.5</code> to dock to one side.</p> </li> <li> <p>Multi-canvas \u2014 call <code>panel.canvas()</code> multiple times.    When several canvases have <code>fit=True</code> (the default), they split the    vertical space equally. No manual height math.</p> </li> <li> <p>Still no callback \u2014 static data only needs <code>bind()</code> + <code>run()</code>.    Dynamic updates come in a later chapter.</p> </li> <li> <p>Drag &amp; drop \u2014 all panels are dockable. Users can rearrange,    float, or resize them at runtime.</p> </li> </ol> <p>Note</p> <p>The same tensor can be bound to multiple canvases at once \u2014 <code>red</code> appears in both the left panel and the right combined panel.</p>"},{"location":"03_training_test/","title":"03 \u2014 Training Test","text":"<p>Example file: <code>examples/03_training_test.py</code></p> <p>Ever stared at a wall of decreasing loss numbers in your terminal for ten minutes, feeling confident, only to discover the model's output is a solid grey rectangle? Yeah, us too.</p> <p>Reading loss values off a scrolling console is about as reliable as reading tea leaves. This chapter puts GT and prediction side by side on screen so you can see whether the network is actually learning.</p>"},{"location":"03_training_test/#what-were-building","title":"What we're building","text":"<p>A tiny MLP (2 \u2192 64 \u2192 64 \u2192 3) fitting a 256\u00d7256 PyTorch logo in real time. The window has three panels:</p> Area Content Left GT panel \u2014 the target image (what you're fitting) Right Prediction panel \u2014 live network output, updated every frame Bottom Info panel \u2014 FPS, loss, iteration, progress bar, and a slider <p>Everything on screen, nothing buried in the terminal.</p>"},{"location":"03_training_test/#new-friends","title":"New friends","text":"<p>Chapters 01 and 02 were all static \u2014 <code>bind()</code> + <code>run()</code>, done. This time we bring two new toys:</p> New thing What it does How to use on_frame Per-frame callback \u2014 train and update here <code>@view.on_frame</code> create_tensor GPU shared-memory tensor <code>vultorch.create_tensor(H, W, ...)</code> <p>Write any PyTorch code inside the callback; Vultorch handles the tensor-to-screen dance every frame.</p>"},{"location":"03_training_test/#full-code","title":"Full code","text":"<pre><code>from pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport vultorch\nui = vultorch.ui\n\ntry:\n    from PIL import Image\nexcept ImportError as exc:\n    raise RuntimeError(\"Please install pillow: pip install pillow\") from exc\n\n\nclass TinyMLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(2, 64),\n            nn.ReLU(inplace=True),\n            nn.Linear(64, 64),\n            nn.ReLU(inplace=True),\n            nn.Linear(64, 3),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nif not torch.cuda.is_available():\n    raise RuntimeError(\"This example needs CUDA\")\n\ndevice = \"cuda\"\n\n# Load the target image\nimg_path = Path(__file__).resolve().parents[1] / \"docs\" / \"images\" / \"pytorch_logo.png\"\nimg = Image.open(img_path).convert(\"RGB\").resize((256, 256), Image.BILINEAR)\ngt = torch.from_numpy(np.asarray(img, dtype=np.float32) / 255.0).to(device)\n\nH, W = gt.shape[0], gt.shape[1]\nys = torch.linspace(-1.0, 1.0, H, device=device)\nxs = torch.linspace(-1.0, 1.0, W, device=device)\nyy, xx = torch.meshgrid(ys, xs, indexing=\"ij\")\ncoords = torch.stack([xx, yy], dim=-1).reshape(-1, 2)  # (H*W, 2)\ntarget = gt.reshape(-1, 3)                               # (H*W, 3)\n\nmodel = TinyMLP().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n\nview = vultorch.View(\"03 - Training Test\", 1280, 760)\ngt_panel = view.panel(\"GT\")\npred_panel = view.panel(\"Prediction\")\n\ngt_panel.canvas(\"gt\").bind(gt)\n\n# 4 channels \u2014 zero-copy GPU display path\npred_rgba = vultorch.create_tensor(H, W, channels=4, device=device,\n                                   name=\"pred\", window=view.window)\npred_rgba[:, :, 3] = 1.0\npred_panel.canvas(\"pred\").bind(pred_rgba)\n\nstate = {\n    \"iter\": 0,\n    \"loss\": 1.0,\n    \"ema\": 1.0,\n    \"steps_per_frame\": 6,\n    \"layout_done\": False,\n}\n\n\n@view.on_frame\ndef train_and_render():\n    # ---- first-frame layout: top row left/right, bottom info ----\n    if not state[\"layout_done\"]:\n        dockspace_id = ui.dock_space_over_viewport(flags=8)\n        ui.dock_builder_remove_node(dockspace_id)\n        ui.dock_builder_add_node(dockspace_id, 1 &lt;&lt; 10)\n        ui.dock_builder_set_node_size(dockspace_id, 1280.0, 760.0)\n\n        info_node, top_node = ui.dock_builder_split_node(dockspace_id, 3, 0.28)\n        left_node, right_node = ui.dock_builder_split_node(top_node, 0, 0.5)\n\n        ui.dock_builder_dock_window(\"GT\", left_node)\n        ui.dock_builder_dock_window(\"Prediction\", right_node)\n        ui.dock_builder_dock_window(\"Info\", info_node)\n        ui.dock_builder_finish(dockspace_id)\n        state[\"layout_done\"] = True\n\n    # ---- train a few steps ----\n    for _ in range(state[\"steps_per_frame\"]):\n        optimizer.zero_grad(set_to_none=True)\n        out = model(coords)\n        loss = F.mse_loss(out, target)\n        loss.backward()\n        optimizer.step()\n\n        state[\"iter\"] += 1\n        state[\"loss\"] = loss.item()\n        state[\"ema\"] = state[\"ema\"] * 0.98 + state[\"loss\"] * 0.02\n\n    # ---- write prediction into the display tensor ----\n    with torch.no_grad():\n        pred = model(coords).reshape(H, W, 3).clamp_(0, 1)\n        pred_rgba[:, :, :3] = pred\n\n    # ---- Info panel ----\n    ui.begin(\"Info\", True, 0)\n    ui.text(f\"FPS: {view.fps:.1f}\")\n    ui.text(f\"Iteration: {state['iter']}\")\n    ui.text(f\"Loss (MSE): {state['loss']:.6f}\")\n    ui.text(f\"EMA Loss: {state['ema']:.6f}\")\n\n    state[\"steps_per_frame\"] = ui.slider_int(\n        \"Steps / Frame\", state[\"steps_per_frame\"], 1, 32\n    )\n    progress = min(1.0, state[\"iter\"] / 3000.0)\n    ui.progress_bar(progress, overlay=f\"Training progress {progress * 100:.1f}%\")\n    ui.text_wrapped(\n        \"Left is GT, right is prediction. Increase 'Steps / Frame' for faster fitting.\"\n    )\n    ui.end()\n\n\nview.run()\n</code></pre> <p>That's it. Run it and watch the grey blob on the right morph into the PyTorch logo in a few seconds.</p>"},{"location":"03_training_test/#what-just-happened","title":"What just happened?","text":"<ol> <li> <p>Data \u2014 PIL loads the image, we convert it to a float32 CUDA tensor    for GT. Pixel coordinates get <code>meshgrid</code>'d into <code>(H*W, 2)</code>, normalized    to <code>[-1, 1]</code>.</p> </li> <li> <p>Model \u2014 a two-hidden-layer MLP (64 wide). Takes <code>(x, y)</code>, outputs    <code>(r, g, b)</code>. Small enough to run inside a per-frame callback without    tanking your framerate.</p> </li> <li> <p>on_frame callback \u2014 called once per frame. It does three things:    set up the dock layout on the first frame, run N training steps, then    write the prediction into <code>pred_rgba</code>.</p> </li> <li> <p>Info panel \u2014 drawn with ImGui's <code>ui.begin()</code> / <code>ui.end()</code>. Text,    sliders, progress bars \u2014 any widget you want, right in the window.</p> </li> </ol>"},{"location":"03_training_test/#key-takeaways","title":"Key takeaways","text":"<ol> <li> <p><code>@view.on_frame</code> \u2014 you can run arbitrary PyTorch code in the    callback. At the end of each frame, Vultorch uploads every bound    tensor to the screen automatically.</p> </li> <li> <p><code>create_tensor</code> \u2014 looks and feels like <code>torch.zeros</code>, but the    underlying memory is Vulkan/CUDA shared. Display is zero-copy.</p> </li> <li> <p>Manual docking \u2014 <code>dock_builder_split_node</code> lets you slice the    window any way you like. Directions: <code>0=left, 1=right, 2=up, 3=down</code>,    ratio is a float.</p> </li> <li> <p>No terminal spam \u2014 all live stats live in the Info panel.    Your console stays clean for warnings and tracebacks.</p> </li> </ol> <p>Tip</p> <p>Crank <code>Steps / Frame</code> up to 32 for blazing-fast convergence. But don't get too greedy \u2014 go too high and your framerate will drop because each frame spends more time training.</p> <p>Note</p> <p><code>create_tensor</code> is called once at init, not every frame. After that you just write into the tensor each frame \u2014 practically free.</p>"},{"location":"api/","title":"API Reference","text":"<p>Complete reference for all public classes and functions in the <code>vultorch</code> package.</p>"},{"location":"api/#module-level-attributes","title":"Module-level Attributes","text":""},{"location":"api/#vultorch__version__","title":"<code>vultorch.__version__</code>","text":"<pre><code>__version__: str\n</code></pre> <p>Package version string (e.g. <code>\"0.5.0\"</code>).</p>"},{"location":"api/#vultorchhas_cuda","title":"<code>vultorch.HAS_CUDA</code>","text":"<pre><code>HAS_CUDA: bool\n</code></pre> <p><code>True</code> if the native extension was compiled with CUDA support. When <code>False</code>, all tensor display falls back to CPU staging (host-visible <code>memcpy</code>).</p>"},{"location":"api/#core-functions","title":"Core Functions","text":""},{"location":"api/#vultorchshow","title":"<code>vultorch.show()</code>","text":"<pre><code>def show(\n    tensor: torch.Tensor,\n    *,\n    name: str = \"tensor\",\n    width: float = 0,\n    height: float = 0,\n    filter: str = \"linear\",\n    window: Window | None = None,\n) -&gt; None\n</code></pre> <p>Display a tensor in the current ImGui context.</p> <p>Parameters:</p> Parameter Type Default Description <code>tensor</code> <code>torch.Tensor</code> (required) CUDA or CPU tensor. dtype: <code>float32</code>, <code>float16</code>, or <code>uint8</code>. Shape: <code>(H, W)</code> or <code>(H, W, C)</code> with C \u2208 {1, 3, 4}. <code>name</code> <code>str</code> <code>\"tensor\"</code> Unique label for caching when showing multiple tensors. <code>width</code> <code>float</code> <code>0</code> Display width in pixels. <code>0</code> = auto-fit to tensor. <code>height</code> <code>float</code> <code>0</code> Display height in pixels. <code>0</code> = auto-fit to tensor. <code>filter</code> <code>str</code> <code>\"linear\"</code> Sampling filter: <code>\"nearest\"</code> or <code>\"linear\"</code>. <code>window</code> <code>Window \\| None</code> <code>None</code> Target window. Defaults to <code>Window._current</code>. <p>Behavior:</p> <ul> <li>1-channel and 3-channel tensors are automatically expanded to RGBA.</li> <li>RGBA expansion buffers are cached per <code>name</code> to avoid per-frame allocation.</li> <li>On CUDA: uses zero-copy GPU\u2192GPU path. On CPU: uses host-visible staging buffer.</li> <li><code>uint8</code> tensors are divided by 255; <code>float16</code> tensors are converted to <code>float32</code>.</li> </ul> <p>Raises: <code>RuntimeError</code> if no active <code>Window</code> exists.</p>"},{"location":"api/#vultorchcreate_tensor","title":"<code>vultorch.create_tensor()</code>","text":"<pre><code>def create_tensor(\n    height: int,\n    width: int,\n    channels: int = 4,\n    device: str = \"cuda:0\",\n    *,\n    name: str = \"tensor\",\n    window: Window | None = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Allocate a Vulkan-shared CUDA tensor for true zero-copy display.</p> <p>Parameters:</p> Parameter Type Default Description <code>height</code> <code>int</code> (required) Tensor height in pixels. <code>width</code> <code>int</code> (required) Tensor width in pixels. <code>channels</code> <code>int</code> <code>4</code> Number of channels: 1, 3, or 4. <code>device</code> <code>str</code> <code>\"cuda:0\"</code> CUDA device string, or <code>\"cpu\"</code>. <code>name</code> <code>str</code> <code>\"tensor\"</code> Texture slot name (must match <code>show(..., name=...)</code>). <code>window</code> <code>Window \\| None</code> <code>None</code> Target window. Defaults to <code>Window._current</code>. <p>Returns: <code>torch.Tensor</code> of shape <code>(height, width, channels)</code>.</p> <p>Note</p> <p>Only <code>channels=4</code> gives true zero-copy via Vulkan external memory. For 1 or 3 channels, a regular CUDA tensor is returned and <code>show()</code> handles RGBA expansion with a GPU\u2192GPU copy.</p> <p>Raises: <code>RuntimeError</code> if no active <code>Window</code> exists.</p>"},{"location":"api/#classes","title":"Classes","text":""},{"location":"api/#vultorchwindow","title":"<code>vultorch.Window</code>","text":"<pre><code>class Window:\n    _current: Window | None   # singleton reference\n\n    def __init__(self, title: str = \"Vultorch\",\n                 width: int = 1280, height: int = 720) -&gt; None: ...\n</code></pre> <p>High-level wrapper around the Vulkan + SDL3 + ImGui engine. Creating a <code>Window</code> automatically makes it the current target for <code>show()</code> and <code>create_tensor()</code>.</p>"},{"location":"api/#methods","title":"Methods","text":"Method Signature Description <code>poll()</code> <code>\u2192 bool</code> Process OS events. Returns <code>False</code> when the window should close. <code>begin_frame()</code> <code>\u2192 bool</code> Begin a new ImGui frame. Returns <code>False</code> if the frame was skipped (minimized). <code>end_frame()</code> <code>\u2192 None</code> Submit the frame to the GPU and present. <code>activate()</code> <code>\u2192 None</code> Make this window the current target for module-level helpers. <code>upload_tensor(tensor, *, name)</code> <code>\u2192 None</code> Upload a tensor for display (CUDA or CPU). <code>get_texture_id(name)</code> <code>\u2192 int</code> ImGui texture ID for a named tensor. <code>get_texture_size(name)</code> <code>\u2192 (int, int)</code> <code>(width, height)</code> for a named tensor. <code>destroy()</code> <code>\u2192 None</code> Release all GPU / window resources. Safe to call multiple times."},{"location":"api/#properties","title":"Properties","text":"Property Type Description <code>tensor_texture_id</code> <code>int</code> ImGui texture ID of the default <code>\"tensor\"</code> slot. <code>tensor_size</code> <code>(int, int)</code> <code>(width, height)</code> of the default <code>\"tensor\"</code> slot."},{"location":"api/#usage","title":"Usage","text":"<pre><code>import vultorch\nfrom vultorch import ui\n\nwin = vultorch.Window(\"Demo\", 1280, 720)\nwhile win.poll():\n    if not win.begin_frame():\n        continue\n    ui.begin(\"Panel\", True, 0)\n    vultorch.show(tensor)\n    ui.end()\n    win.end_frame()\nwin.destroy()\n</code></pre>"},{"location":"api/#vultorchcamera","title":"<code>vultorch.Camera</code>","text":"<pre><code>class Camera:\n    azimuth: float     # horizontal angle (radians), default 0.0\n    elevation: float   # vertical angle (radians), default 0.6\n    distance: float    # distance from target, default 3.0\n    target: tuple      # (x, y, z) look-at point, default (0, 0, 0)\n    fov: float         # field of view (degrees), default 45.0\n</code></pre> <p>Orbit camera parameters used by <code>SceneView</code>. Call <code>reset()</code> to restore defaults.</p>"},{"location":"api/#vultorchlight","title":"<code>vultorch.Light</code>","text":"<pre><code>class Light:\n    direction: tuple   # (x, y, z), default (0.3, -1.0, 0.5)\n    color: tuple       # (r, g, b), default (1, 1, 1)\n    intensity: float   # default 1.0\n    ambient: float     # ambient term, default 0.15\n    specular: float    # specular term, default 0.5\n    shininess: float   # Blinn-Phong exponent, default 32.0\n    enabled: bool      # default True\n</code></pre> <p>Blinn-Phong directional light parameters used by <code>SceneView</code>.</p>"},{"location":"api/#vultorchsceneview","title":"<code>vultorch.SceneView</code>","text":"<pre><code>class SceneView:\n    def __init__(self, name: str = \"SceneView\",\n                 width: int = 800, height: int = 600,\n                 msaa: int = 4) -&gt; None: ...\n</code></pre> <p>3D tensor viewer \u2014 renders a tensor on a lit plane with orbit camera and MSAA.</p>"},{"location":"api/#attributes","title":"Attributes","text":"Attribute Type Default Description <code>name</code> <code>str</code> <code>\"SceneView\"</code> ImGui window label. <code>camera</code> <code>Camera</code> (auto) Orbit camera (drag to rotate). <code>light</code> <code>Light</code> (auto) Directional light. <code>background</code> <code>tuple</code> <code>(0.12, 0.12, 0.14)</code> Background color <code>(r, g, b)</code>. <code>msaa</code> <code>int</code> <code>4</code> Multi-sample anti-aliasing level (1/2/4/8)."},{"location":"api/#methods_1","title":"Methods","text":"Method Description <code>set_tensor(tensor)</code> Upload a tensor to the scene's texture. <code>render()</code> Process mouse interaction, render the scene, and display as an ImGui image."},{"location":"api/#usage_1","title":"Usage","text":"<pre><code>scene = vultorch.SceneView(\"3D View\", 800, 600, msaa=4)\n# inside frame loop:\nscene.set_tensor(tensor)\nscene.render()\n</code></pre>"},{"location":"api/#declarative-api","title":"Declarative API","text":"<p>The declarative API provides a higher-level abstraction for building multi-panel visualization apps.</p>"},{"location":"api/#vultorchview","title":"<code>vultorch.View</code>","text":"<pre><code>class View:\n    def __init__(self, title: str = \"Vultorch\",\n                 width: int = 1280, height: int = 720) -&gt; None: ...\n</code></pre> <p>Top-level window with automatic docking layout.</p>"},{"location":"api/#methods_2","title":"Methods","text":"Method Signature Description <code>panel(name, *, side, width)</code> <code>\u2192 Panel</code> Create or retrieve a dockable panel. <code>side</code>: <code>\"left\"</code> / <code>\"right\"</code> / <code>None</code>. <code>on_frame(fn)</code> <code>\u2192 fn</code> Decorator \u2014 register a per-frame callback. <code>run()</code> <code>\u2192 None</code> Blocking event loop. <code>step()</code> <code>\u2192 bool</code> Non-blocking: process one frame. Returns <code>False</code> on close. <code>end_step()</code> <code>\u2192 None</code> Finish the frame started by <code>step()</code>. <code>close()</code> <code>\u2192 None</code> Destroy the window."},{"location":"api/#properties_1","title":"Properties","text":"Property Type Description <code>fps</code> <code>float</code> Current frames per second. <code>time</code> <code>float</code> Elapsed time in seconds. <code>window</code> <code>Window</code> Underlying <code>Window</code> instance."},{"location":"api/#usage-blocking","title":"Usage \u2014 Blocking","text":"<pre><code>view = vultorch.View(\"Demo\", 1280, 720)\nview.panel(\"Viewer\").canvas(\"img\").bind(tensor)\n\n@view.on_frame\ndef update():\n    speed = controls.slider(\"Speed\", 0, 10)\n    tensor[:,:,0] = (x + view.time * speed).sin()\n\nview.run()\n</code></pre>"},{"location":"api/#usage-training-loop","title":"Usage \u2014 Training Loop","text":"<pre><code>view = vultorch.View(\"Train\", 1024, 768)\noutput = view.panel(\"Output\").canvas(\"result\")\nfor epoch in range(100):\n    result = model(input)\n    output.bind(result)\n    if not view.step():\n        break\n    view.end_step()\nview.close()\n</code></pre>"},{"location":"api/#vultorchpanel","title":"<code>vultorch.Panel</code>","text":"<pre><code>class Panel:\n    # Created via View.panel() \u2014 not instantiated directly\n</code></pre> <p>A dockable panel containing canvases and widgets.</p>"},{"location":"api/#canvas-factory","title":"Canvas Factory","text":"Method Signature Description <code>canvas(name, *, filter, fit)</code> <code>\u2192 Canvas</code> Create a named canvas. <code>filter</code>: <code>\"linear\"</code> / <code>\"nearest\"</code>. <code>fit</code>: auto-fill panel space."},{"location":"api/#layout","title":"Layout","text":"Method Description <code>row()</code> Context manager \u2014 place child widgets side-by-side."},{"location":"api/#widgets","title":"Widgets","text":"<p>All widget methods manage state automatically across frames.</p> Method Signature Description <code>text(text)</code> <code>\u2192 None</code> Static text. <code>text_colored(r, g, b, a, text)</code> <code>\u2192 None</code> Colored text. <code>text_wrapped(text)</code> <code>\u2192 None</code> Auto-wrapping text. <code>separator()</code> <code>\u2192 None</code> Horizontal separator line. <code>button(label)</code> <code>\u2192 bool</code> Button. Returns <code>True</code> when clicked. <code>checkbox(label, *, default)</code> <code>\u2192 bool</code> Checkbox with stateful toggle. <code>slider(label, min, max, *, default)</code> <code>\u2192 float</code> Float slider. <code>slider_int(label, min, max, *, default)</code> <code>\u2192 int</code> Integer slider. <code>color_picker(label, *, default)</code> <code>\u2192 (r, g, b)</code> Color picker (3-float tuple). <code>combo(label, items, *, default)</code> <code>\u2192 int</code> Dropdown combo box. Returns selected index. <code>input_text(label, *, default, max_length)</code> <code>\u2192 str</code> Text input field. <code>plot(values, *, label, overlay, width, height)</code> <code>\u2192 None</code> Line plot from a list of floats. <code>progress(fraction, *, overlay)</code> <code>\u2192 None</code> Progress bar (0.0 \u2013 1.0)."},{"location":"api/#vultorchcanvas","title":"<code>vultorch.Canvas</code>","text":"<pre><code>class Canvas:\n    # Created via Panel.canvas() \u2014 not instantiated directly\n</code></pre> <p>A display surface that renders a bound tensor as an ImGui image.</p>"},{"location":"api/#methods_3","title":"Methods","text":"Method Signature Description <code>bind(tensor)</code> <code>\u2192 Canvas</code> Bind a tensor for display. Returns <code>self</code> for chaining. <code>alloc(height, width, channels, device)</code> <code>\u2192 torch.Tensor</code> Allocate Vulkan-shared memory and auto-bind. Returns the tensor."},{"location":"api/#properties_2","title":"Properties","text":"Property Type Default Description <code>filter</code> <code>str</code> <code>\"linear\"</code> <code>\"linear\"</code> or <code>\"nearest\"</code>. <code>fit</code> <code>bool</code> <code>True</code> Auto-fill available panel space."},{"location":"api/#imgui-bindings-vultorchui","title":"ImGui Bindings (<code>vultorch.ui</code>)","text":"<p>The <code>vultorch.ui</code> submodule exposes Dear ImGui functions (docking branch). All functions map directly to their ImGui C++ counterparts.</p>"},{"location":"api/#windows","title":"Windows","text":"<pre><code>ui.begin(name: str, opened: bool = True, flags: int = 0) -&gt; tuple[bool, bool]\nui.end() -&gt; None\nui.begin_child(id: str, width=0.0, height=0.0, child_flags=0, window_flags=0) -&gt; bool\nui.end_child() -&gt; None\n</code></pre>"},{"location":"api/#text","title":"Text","text":"<pre><code>ui.text(text: str) -&gt; None\nui.text_colored(r, g, b, a, text: str) -&gt; None\nui.text_disabled(text: str) -&gt; None\nui.text_wrapped(text: str) -&gt; None\nui.label_text(label: str, text: str) -&gt; None\nui.bullet_text(text: str) -&gt; None\n</code></pre>"},{"location":"api/#buttons","title":"Buttons","text":"<pre><code>ui.button(label: str, width=0.0, height=0.0) -&gt; bool\nui.small_button(label: str) -&gt; bool\nui.invisible_button(id: str, width, height) -&gt; bool\nui.arrow_button(id: str, direction: int) -&gt; bool\nui.radio_button(label: str, active: bool) -&gt; bool\n</code></pre>"},{"location":"api/#inputs","title":"Inputs","text":"<pre><code>ui.checkbox(label, value: bool) -&gt; bool\nui.slider_float(label, value, min=0.0, max=1.0, format=\"%.3f\") -&gt; float\nui.slider_float2(label, v1, v2, min, max) -&gt; tuple[float, float]\nui.slider_float3(label, v1, v2, v3, min, max) -&gt; tuple[float, float, float]\nui.slider_float4(label, v1, v2, v3, v4, min, max) -&gt; tuple\nui.slider_int(label, value, min=0, max=100) -&gt; int\nui.slider_angle(label, value, min=-360, max=360) -&gt; float\nui.drag_float(label, value, speed=1.0) -&gt; float\nui.drag_float2(label, v1, v2, speed=1.0) -&gt; tuple\nui.drag_float3(label, v1, v2, v3, speed=1.0) -&gt; tuple\nui.drag_int(label, value, speed=1.0) -&gt; int\nui.input_float(label, value) -&gt; float\nui.input_float2(label, v1, v2) -&gt; tuple\nui.input_float3(label, v1, v2, v3) -&gt; tuple\nui.input_float4(label, v1, v2, v3, v4) -&gt; tuple\nui.input_int(label, value) -&gt; int\nui.input_text(label, text, max_length=256) -&gt; str\nui.input_text_multiline(label, text, max_length=1024) -&gt; str\n</code></pre>"},{"location":"api/#colors","title":"Colors","text":"<pre><code>ui.color_edit3(label, r, g, b, flags=0) -&gt; tuple[float, float, float]\nui.color_edit4(label, r, g, b, a, flags=0) -&gt; tuple[float, float, float, float]\nui.color_picker3(label, r, g, b, flags=0) -&gt; tuple[float, float, float]\nui.color_picker4(label, r, g, b, a, flags=0) -&gt; tuple\n</code></pre>"},{"location":"api/#selection","title":"Selection","text":"<pre><code>ui.combo(label, current: int, items: list[str]) -&gt; int\nui.listbox(label, current: int, items: list[str], height_items=-1) -&gt; int\nui.tree_node(label: str) -&gt; bool\nui.tree_pop() -&gt; None\nui.collapsing_header(label: str) -&gt; bool\nui.selectable(label: str, selected: bool = False) -&gt; bool\n</code></pre>"},{"location":"api/#tabs","title":"Tabs","text":"<pre><code>ui.begin_tab_bar(id: str) -&gt; bool\nui.end_tab_bar() -&gt; None\nui.begin_tab_item(label: str) -&gt; bool\nui.end_tab_item() -&gt; None\n</code></pre>"},{"location":"api/#display","title":"Display","text":"<pre><code>ui.progress_bar(fraction, sx=-1.0, sy=0.0, overlay=\"\")\nui.image(texture_id: int, width, height, uv0x=0, uv0y=0, uv1x=1, uv1y=1)\nui.image_button(id: str, texture_id: int, width, height) -&gt; bool\nui.plot_lines(label, values: list[float], offset=0, overlay=\"\", ...)\nui.plot_histogram(label, values: list[float], offset=0, overlay=\"\", ...)\n</code></pre>"},{"location":"api/#layout_1","title":"Layout","text":"<pre><code>ui.separator()\nui.same_line(offset=0.0, spacing=-1.0)\nui.new_line()\nui.spacing()\nui.dummy(width, height)\nui.indent(width=0.0)\nui.unindent(width=0.0)\nui.begin_group()\nui.end_group()\nui.push_item_width(width)\nui.pop_item_width()\nui.columns(count=1, id=None, border=True)\nui.next_column()\n</code></pre>"},{"location":"api/#tables","title":"Tables","text":"<pre><code>ui.begin_table(id: str, columns: int, flags=0) -&gt; bool\nui.end_table()\nui.table_next_row(flags=0, min_row_height=0.0)\nui.table_next_column() -&gt; bool\nui.table_set_column_index(index: int) -&gt; bool\nui.table_setup_column(label: str, flags=0, init_width=0.0)\nui.table_headers_row()\n</code></pre>"},{"location":"api/#menus","title":"Menus","text":"<pre><code>ui.begin_main_menu_bar() -&gt; bool\nui.end_main_menu_bar()\nui.begin_menu_bar() -&gt; bool\nui.end_menu_bar()\nui.begin_menu(label: str, enabled=True) -&gt; bool\nui.end_menu()\nui.menu_item(label: str, shortcut=\"\", selected=False, enabled=True) -&gt; bool\n</code></pre>"},{"location":"api/#popups","title":"Popups","text":"<pre><code>ui.open_popup(id: str)\nui.begin_popup(id: str) -&gt; bool\nui.begin_popup_modal(name: str, flags=0) -&gt; bool\nui.end_popup()\nui.close_current_popup()\n</code></pre>"},{"location":"api/#tooltips","title":"Tooltips","text":"<pre><code>ui.begin_tooltip()\nui.end_tooltip()\nui.set_tooltip(text: str)\n</code></pre>"},{"location":"api/#id-stack","title":"ID Stack","text":"<pre><code>ui.push_id_str(id: str)\nui.push_id_int(id: int)\nui.pop_id()\nui.get_id(id: str) -&gt; int\n</code></pre>"},{"location":"api/#style","title":"Style","text":"<pre><code>ui.push_style_color(idx: int, r, g, b, a)\nui.pop_style_color(count=1)\nui.push_style_var_float(idx: int, value: float)\nui.push_style_var_vec2(idx: int, x: float, y: float)\nui.pop_style_var(count=1)\nui.style_colors_dark()\nui.style_colors_light()\nui.style_colors_classic()\n</code></pre>"},{"location":"api/#cursor-window-info","title":"Cursor &amp; Window Info","text":"<pre><code>ui.get_cursor_pos() -&gt; tuple[float, float]\nui.set_cursor_pos(x, y)\nui.get_content_region_avail() -&gt; tuple[float, float]\nui.get_window_size() -&gt; tuple[float, float]\nui.get_window_pos() -&gt; tuple[float, float]\nui.set_next_window_pos(x, y, cond=0)\nui.set_next_window_size(width, height, cond=0)\n</code></pre>"},{"location":"api/#docking","title":"Docking","text":"<pre><code>ui.dock_space_over_viewport(flags=0) -&gt; int\nui.dock_space(id: int, sx=0.0, sy=0.0, flags=0) -&gt; int\nui.set_next_window_dock_id(dock_id: int, cond=0)\nui.dock_builder_add_node(node_id=0, flags=0) -&gt; int\nui.dock_builder_remove_node(node_id: int)\nui.dock_builder_set_node_size(node_id, width, height)\nui.dock_builder_set_node_pos(node_id, x, y)\nui.dock_builder_split_node(node_id, split_dir, ratio) -&gt; tuple[int, int]\nui.dock_builder_dock_window(window_name: str, node_id: int)\nui.dock_builder_finish(node_id: int)\nui.dock_builder_get_node(node_id: int) -&gt; int\n</code></pre>"},{"location":"api/#drawing","title":"Drawing","text":"<pre><code>ui.draw_line(x1, y1, x2, y2, col=0xFFFFFFFF, thickness=1.0)\nui.draw_rect(x1, y1, x2, y2, col=0xFFFFFFFF)\nui.draw_rect_filled(x1, y1, x2, y2, col=0xFFFFFFFF)\nui.draw_circle(cx, cy, radius, col=0xFFFFFFFF)\nui.draw_circle_filled(cx, cy, radius, col=0xFFFFFFFF)\nui.draw_text(x, y, col: int, text: str)\nui.bg_draw_image(texture_id, x1, y1, x2, y2)\n</code></pre>"},{"location":"api/#input-state","title":"Input State","text":"<pre><code>ui.is_item_hovered() -&gt; bool\nui.is_item_active() -&gt; bool\nui.is_item_clicked() -&gt; bool\nui.is_item_focused() -&gt; bool\nui.is_item_edited() -&gt; bool\nui.is_item_deactivated_after_edit() -&gt; bool\nui.get_mouse_pos() -&gt; tuple[float, float]\nui.is_mouse_clicked(button: int) -&gt; bool\nui.is_mouse_double_clicked(button: int) -&gt; bool\nui.is_mouse_dragging(button: int, lock_threshold=-1.0) -&gt; bool\nui.get_mouse_drag_delta(button=0, lock_threshold=-1.0) -&gt; tuple[float, float]\nui.is_key_pressed(key: int) -&gt; bool\nui.is_key_down(key: int) -&gt; bool\n</code></pre>"},{"location":"api/#utility","title":"Utility","text":"<pre><code>ui.get_io_framerate() -&gt; float\nui.get_io_delta_time() -&gt; float\nui.get_time() -&gt; float\nui.get_frame_count() -&gt; int\nui.get_display_size() -&gt; tuple[float, float]\nui.col32(r: int, g: int, b: int, a: int = 255) -&gt; int\nui.show_demo_window()\nui.show_metrics_window()\n</code></pre>"},{"location":"api/#internal-helpers","title":"Internal Helpers","text":""},{"location":"api/#vultorch_normalize_tensor","title":"<code>vultorch._normalize_tensor()</code>","text":"<pre><code>def _normalize_tensor(tensor) -&gt; tuple[Tensor, int, int, int]\n</code></pre> <p>Normalize tensor dtype and shape for display. Returns <code>(tensor, height, width, channels)</code>.</p> <ul> <li>Converts <code>uint8</code> \u2192 <code>float32</code> (\u00f7 255), <code>float16</code> \u2192 <code>float32</code>.</li> <li>Accepts 2D <code>(H, W)</code> and 3D <code>(H, W, C)</code> with C \u2208 {1, 3, 4}.</li> <li>Raises <code>ValueError</code> for unsupported dtype, shape, or channel count.</li> </ul>"},{"location":"zh/","title":"Vultorch \u6559\u7a0b","text":"<p>\u9010\u6b65\u5b66\u4e60 Vultorch\uff0c\u6bcf\u4e2a\u7ae0\u8282\u5bf9\u5e94 <code>examples/</code> \u76ee\u5f55\u4e2d\u7684\u4e00\u4e2a\u53ef\u8fd0\u884c\u811a\u672c\u3002</p> \u7ae0\u8282 \u4e3b\u9898 \u6838\u5fc3\u6982\u5ff5 01 \u2014 Hello Tensor \u6700\u5c0f\u793a\u4f8b View, Panel, Canvas, bind, run 02 \u2014 \u591a\u9762\u677f \u591a\u9762\u677f\u4e0e\u591a\u753b\u5e03 \u5e03\u5c40, side, \u591a\u753b\u5e03 03 \u2014 \u8bad\u7ec3\u6d4b\u8bd5 \u62df\u5408 GT \u56fe\u50cf \u81ea\u5b9a\u4e49\u505c\u9760\u5e03\u5c40, create_tensor, \u9010\u50cf\u7d20\u4f18\u5316 <p>\u66f4\u591a\u7ae0\u8282\u5373\u5c06\u63a8\u51fa\u3002</p>"},{"location":"zh/01_hello_tensor/","title":"01 \u2014 Hello Tensor","text":"<p>\u793a\u4f8b\u6587\u4ef6\uff1a <code>examples/01_hello_tensor.py</code></p> <p>\u4f60\u662f\u5426\u53d7\u591f\u4e86\u6bcf\u4e2a\u4ed3\u5e93\u90fd\u6709\u4e00\u5957\u81ea\u5df1\u5b9e\u73b0\u7684\u53ef\u89c6\u5316\u65b9\u6848 \u2014\u2014 \u8fd9\u4e2a\u7528 matplotlib \u624b\u52a8\u5237\u65b0\uff0c \u90a3\u4e2a\u7528 <code>cv2.imshow</code> \u7136\u540e <code>waitKey(1)</code>\uff0c\u8fd8\u6709\u7684\u76f4\u63a5\u5b58 PNG \u8ba9\u4f60\u5f00\u4e2a\u56fe\u7247\u67e5\u770b\u5668\uff1f</p> <p>Vultorch \u53ea\u9700 \u56db\u884c\u4ee3\u7801 \u5c31\u628a CUDA tensor \u642c\u5230\u5c4f\u5e55\u4e0a\u3002\u4e0d\u5b58\u56fe\u3001\u4e0d\u8fc7 CPU\u3001 \u4e0d\u9700\u8981 <code>plt.pause(0.001)</code> \u8fd9\u79cd\u9ed1\u9b54\u6cd5\u3002</p>"},{"location":"zh/01_hello_tensor/#_1","title":"\u4f60\u9700\u8981\u8bb0\u4f4f\u7684\u4e1c\u897f","text":"<p>\u4e00\u5171\u5c31\u56db\u4e2a\u5bf9\u8c61\uff1a</p> \u5bf9\u8c61 \u662f\u4ec0\u4e48 \u5199\u6cd5 View \u64cd\u4f5c\u7cfb\u7edf\u7a97\u53e3 <code>vultorch.View(\"title\", w, h)</code> Panel View \u91cc\u53ef\u505c\u9760\u7684\u5b50\u7a97\u53e3 <code>view.panel(\"name\")</code> Canvas Panel \u91cc\u7684 GPU \u56fe\u50cf\u69fd\u4f4d <code>panel.canvas(\"name\")</code> bind() \u628a tensor \u8fde\u5230 Canvas \u4e0a <code>canvas.bind(t)</code> <p>\u94fe\u8d77\u6765\uff0c\u8c03 <code>run()</code>\uff0c\u6536\u5de5\u3002</p>"},{"location":"zh/01_hello_tensor/#_2","title":"\u5b8c\u6574\u4ee3\u7801","text":"<pre><code>import torch\nimport vultorch\n\n# \u4e00\u5f20 256\u00d7256 \u7684 RGB \u6e10\u53d8 \u2014 \u4efb\u4f55 (H,W,C) float32 CUDA tensor \u90fd\u884c\nH, W = 256, 256\nx = torch.linspace(0, 1, W, device=\"cuda\")\ny = torch.linspace(0, 1, H, device=\"cuda\")\nt = torch.stack([\n    x.unsqueeze(0).expand(H, W),\n    y.unsqueeze(1).expand(H, W),\n    torch.full((H, W), 0.3, device=\"cuda\"),\n], dim=-1)  # (256, 256, 3)\n\nview   = vultorch.View(\"01 - Hello Tensor\", 512, 512)\npanel  = view.panel(\"Viewer\")\ncanvas = panel.canvas(\"gradient\")\ncanvas.bind(t)\nview.run()  # \u963b\u585e\uff0c\u76f4\u5230\u4f60\u5173\u95ed\u7a97\u53e3\n</code></pre> <p>\u6ca1\u4e86\u3002\u4e0d\u9700\u8981\u624b\u5199\u4e8b\u4ef6\u5faa\u73af\uff0c\u4e0d\u9700\u8981 <code>begin_frame()</code> / <code>end_frame()</code>\u3002</p>"},{"location":"zh/01_hello_tensor/#_3","title":"\u521a\u624d\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f","text":"<ol> <li> <p>\u6570\u636e \u2014 \u6211\u4eec\u5728 CUDA \u4e0a\u9020\u4e86\u4e00\u5f20 RGB \u6e10\u53d8\u3002Vultorch \u652f\u6301    <code>(H,W)</code> / <code>(H,W,1)</code> / <code>(H,W,3)</code> / <code>(H,W,4)</code>\uff0c    float32 / float16 / uint8 \u90fd\u884c\uff0cRGBA \u6269\u5c55\u5b83\u81ea\u5df1\u641e\u5b9a\u3002</p> </li> <li> <p>\u5bf9\u8c61\u6811 \u2014 <code>View</code> \u2192 <code>Panel</code> \u2192 <code>Canvas</code> \u2192 <code>bind(tensor)</code>\u3002    \u753b\u5e03\u9ed8\u8ba4\u94fa\u6ee1\u6574\u4e2a\u9762\u677f\uff08<code>fit=True</code>\uff09\u3002</p> </li> <li> <p>\u8fd0\u884c \u2014 <code>view.run()</code> \u8fdb\u5165\u963b\u585e\u4e8b\u4ef6\u5faa\u73af\uff0c\u6bcf\u5e27\u91cd\u65b0\u4e0a\u4f20 tensor \u5e76\u6e32\u67d3\u3002    \u5173\u7a97\u53e3\u5c31\u9000\u51fa\u3002</p> </li> </ol> <p>\u63d0\u793a</p> <p>\u56db\u884c\u521d\u59cb\u5316\u53ef\u4ee5\u538b\u6210\u4e00\u884c\uff0c\u5982\u679c\u4f60\u559c\u6b22\u70ab\u6280\u7684\u8bdd\uff1a <code>view.panel(\"Viewer\").canvas(\"gradient\").bind(t)</code></p>"},{"location":"zh/02_multi_panel/","title":"02 \u2014 \u591a\u9762\u677f","text":"<p>\u793a\u4f8b\u6587\u4ef6\uff1a <code>examples/02_imgui_controls.py</code></p> <p>\u4e00\u4e2a\u9762\u677f\u633a\u597d\u7684\u3002\u4f46\u5b9e\u9645\u505a\u7814\u7a76\u7684\u65f6\u5019\uff0c\u4f60\u60f3\u540c\u65f6\u770b loss map\u3001\u68af\u5ea6\u573a\u3001 \u6a21\u578b\u8f93\u51fa \u2014\u2014 \u800c\u4e14\u6700\u597d\u4e0d\u7528\u81ea\u5df1\u5199\u4efb\u4f55\u5e03\u5c40\u4ee3\u7801\u3002</p> <p>\u597d\u6d88\u606f\uff1aVultorch \u7684\u9762\u677f\u662f\u53ef\u505c\u9760\u7684\u3002\u4f60\u53ea\u7ba1\u521b\u5efa\uff0c\u5b83\u4eec\u81ea\u5df1\u6392\u597d\u3002 \u7528\u6237\u8fd0\u884c\u65f6\u8fd8\u80fd\u968f\u4fbf\u62d6\u3001\u968f\u4fbf\u62c9\u3002</p> <p>\u672c\u7ae0\u6f14\u793a\u4e24\u79cd\u6a21\u5f0f\uff1a</p> <ul> <li>\u6bcf\u4e2a\u9762\u677f\u4e00\u4e2a\u753b\u5e03 \u2014 \u4e09\u4e2a\u9762\u677f\u5782\u76f4\u5806\u53e0\uff0c\u5404\u81ea\u4e00\u5f20\u56fe\u3002</li> <li>\u4e00\u4e2a\u9762\u677f\u591a\u4e2a\u753b\u5e03 \u2014 \u4e00\u4e2a\u9762\u677f\u91cc\u585e\u4e09\u4e2a\u753b\u5e03\uff0c\u81ea\u52a8\u5747\u5206\u3002</li> </ul>"},{"location":"zh/02_multi_panel/#_1","title":"\u5e03\u5c40","text":"<p>\u7a97\u53e3\u957f\u8fd9\u6837\uff1a</p> \u5de6\u4fa7\uff08\u4e3b\u533a\u57df\uff09 \u53f3\u4fa7\uff08<code>side=\"right\"</code>\uff09 Red \u9762\u677f \u2014 <code>red_img</code> Combined \u9762\u677f Green \u9762\u677f \u2014 <code>green_img</code> <code>c_red</code> \u753b\u5e03 Blue \u9762\u677f \u2014 <code>blue_img</code> <code>c_green</code> \u753b\u5e03 <code>c_blue</code> \u753b\u5e03 <p>\u5de6\u8fb9\uff1a3 \u4e2a\u72ec\u7acb\u9762\u677f\uff0c\u5404\u4e00\u4e2a\u753b\u5e03\u3002\u53f3\u8fb9\uff1a1 \u4e2a\u9762\u677f\uff0c3 \u4e2a\u753b\u5e03\u5171\u4eab\u7a7a\u95f4\u3002</p>"},{"location":"zh/02_multi_panel/#_2","title":"\u5b8c\u6574\u4ee3\u7801","text":"<pre><code>import torch\nimport vultorch\n\nH, W = 128, 128\ndevice = \"cuda\"\n\n# \u4e09\u5f20\u4e0d\u540c\u7684 tensor\nx = torch.linspace(0, 1, W, device=device)\nred = torch.zeros(H, W, 3, device=device)\nred[:, :, 0] = x.unsqueeze(0).expand(H, W)\n\ny = torch.linspace(0, 1, H, device=device)\ngreen = torch.zeros(H, W, 3, device=device)\ngreen[:, :, 1] = y.unsqueeze(1).expand(H, W)\n\nblue = torch.zeros(H, W, 3, device=device)\ncx = (torch.arange(W, device=device) // 32) % 2\ncy = (torch.arange(H, device=device) // 32) % 2\nblue[:, :, 2] = (cx.unsqueeze(0) ^ cy.unsqueeze(1)).float()\n\nview = vultorch.View(\"02 - Multi-Panel\", 1200, 600)\n\n# \u5de6\u4fa7\uff1a3 \u4e2a\u9762\u677f\uff0c\u5404\u4e00\u4e2a\u753b\u5e03\npanel_r = view.panel(\"Red\")\npanel_g = view.panel(\"Green\")\npanel_b = view.panel(\"Blue\")\npanel_r.canvas(\"red_img\").bind(red)\npanel_g.canvas(\"green_img\").bind(green)\npanel_b.canvas(\"blue_img\").bind(blue)\n\n# \u53f3\u4fa7\uff1a1 \u4e2a\u9762\u677f\uff0c3 \u4e2a\u753b\u5e03\uff08\u81ea\u52a8\u5782\u76f4\u5747\u5206\uff09\ncombined = view.panel(\"Combined\", side=\"right\", width=0.5)\ncombined.canvas(\"c_red\").bind(red)\ncombined.canvas(\"c_green\").bind(green)\ncombined.canvas(\"c_blue\").bind(blue)\n\nview.run()\n</code></pre>"},{"location":"zh/02_multi_panel/#_3","title":"\u8981\u70b9","text":"<ol> <li> <p>\u81ea\u52a8\u5e03\u5c40 \u2014 \u4e0d\u5199 <code>side=</code> \u7684\u9762\u677f\u81ea\u52a8\u5782\u76f4\u5806\u53e0\u3002    \u52a0 <code>side=\"right\"</code> + <code>width=0.5</code> \u5c31\u505c\u9760\u5230\u53f3\u8fb9\u5360\u4e00\u534a\u3002</p> </li> <li> <p>\u591a\u753b\u5e03 \u2014 \u5bf9\u540c\u4e00\u4e2a\u9762\u677f\u591a\u6b21\u8c03\u7528 <code>panel.canvas()</code>\u3002    \u591a\u4e2a <code>fit=True</code>\uff08\u9ed8\u8ba4\uff09\u7684\u753b\u5e03\u4f1a\u81ea\u52a8\u5747\u5206\u5782\u76f4\u7a7a\u95f4\uff0c\u4e0d\u7528\u624b\u7b97\u9ad8\u5ea6\u3002</p> </li> <li> <p>\u4f9d\u7136\u4e0d\u9700\u8981\u56de\u8c03 \u2014 \u9759\u6001\u6570\u636e\u53ea\u9700 <code>bind()</code> + <code>run()</code>\u3002    \u52a8\u6001\u66f4\u65b0\u540e\u9762\u7684\u7ae0\u8282\u4f1a\u8bb2\u3002</p> </li> <li> <p>\u968f\u4fbf\u62d6 \u2014 \u6240\u6709\u9762\u677f\u90fd\u652f\u6301\u505c\u9760\u3002\u7528\u6237\u53ef\u4ee5\u62d6\u6807\u9898\u680f\u91cd\u6392\u3001    \u62c9\u51fa\u6765\u53d8\u6d6e\u52a8\u7a97\u53e3\u3001\u6216\u8005\u62d6\u8fb9\u6846\u8c03\u5927\u5c0f\u3002</p> </li> </ol> <p>\u8bf4\u660e</p> <p>\u540c\u4e00\u4e2a tensor \u53ef\u4ee5\u540c\u65f6\u7ed1\u5b9a\u591a\u4e2a\u753b\u5e03 \u2014\u2014 <code>red</code> \u540c\u65f6\u51fa\u73b0\u5728\u5de6\u8fb9\u7684 Red \u9762\u677f\u548c\u53f3\u8fb9\u7684 Combined \u9762\u677f\u91cc\u3002</p>"},{"location":"zh/03_training_test/","title":"03 \u2014 \u8bad\u7ec3\u6d4b\u8bd5","text":"<p>\u793a\u4f8b\u6587\u4ef6\uff1a <code>examples/03_training_test.py</code></p> <p>\u4f60\u6709\u6ca1\u6709\u7ecf\u5386\u8fc7\u8fd9\u79cd\u4e8b\uff1a\u8bad\u7ec3\u8dd1\u4e86\u534a\u5c0f\u65f6\uff0c\u7ec8\u7aef\u91cc loss \u6570\u5b57\u54d7\u54d7\u5f80\u4e0b\u6389\uff0c \u770b\u8d77\u6765\u633a\u6b63\u5e38 \u2014\u2014 \u7ed3\u679c\u4e00\u51fa\u56fe\u53d1\u73b0\u6a21\u578b\u8f93\u51fa\u5168\u662f\u7070\u7684\uff1f</p> <p>\u76ef\u7740\u547d\u4ee4\u884c\u91cc\u7684\u6570\u5b57\u731c\u6a21\u578b\u72b6\u6001\uff0c\u8ddf\u770b\u80a1\u7968 K \u7ebf\u731c\u660e\u5929\u6da8\u8dcc\u4e00\u6837\u4e0d\u9760\u8c31\u3002 \u672c\u7ae0\u76f4\u63a5\u628a GT \u548c\u9884\u6d4b\u5e76\u6392\u653e\u5728\u5c4f\u5e55\u4e0a\u3002\u7f51\u7edc\u5230\u5e95\u6709\u6ca1\u6709\u5728\u5b66\uff0c\u4e00\u773c\u5c31\u77e5\u9053\u3002</p>"},{"location":"zh/03_training_test/#_1","title":"\u8fd9\u6b21\u73a9\u4ec0\u4e48","text":"<p>\u4e00\u4e2a\u5f88\u5c0f\u7684 MLP\uff082 \u2192 64 \u2192 64 \u2192 3\uff09\u53bb\u5b9e\u65f6\u62df\u5408\u4e00\u5f20 256\u00d7256 \u7684 PyTorch logo\u3002 \u7a97\u53e3\u5206\u4e09\u5757\uff1a</p> \u533a\u57df \u5185\u5bb9 \u5de6\u4fa7 GT \u9762\u677f \u2014 \u76ee\u6807\u56fe\uff08\u4f60\u8981\u62df\u5408\u7684\u4e1c\u897f\uff09 \u53f3\u4fa7 Prediction \u9762\u677f \u2014 \u7f51\u7edc\u5b9e\u65f6\u8f93\u51fa\uff0c\u6bcf\u5e27\u5237\u65b0 \u4e0b\u65b9 Info \u9762\u677f \u2014 FPS\u3001loss\u3001\u8fed\u4ee3\u6b21\u6570\u3001\u8fdb\u5ea6\u6761\uff0c\u8fd8\u80fd\u62d6\u6ed1\u6761 <p>\u6240\u6709\u6570\u503c\u90fd\u5728\u753b\u9762\u91cc\uff0c\u4e0d\u7528\u518d\u5728\u7ec8\u7aef\u91cc\u7ffb\u6765\u7ffb\u53bb\u627e\u3002</p>"},{"location":"zh/03_training_test/#_2","title":"\u65b0\u670b\u53cb","text":"<p>\u524d\u4e24\u7ae0\u90fd\u662f\u9759\u6001\u6570\u636e \u2014\u2014 <code>bind()</code> + <code>run()</code>\uff0c\u5b8c\u4e8b\u3002 \u8fd9\u6b21\u6211\u4eec\u8981\u5f15\u5165\u4e24\u4e2a\u65b0\u4e1c\u897f\uff1a</p> \u65b0\u4e1c\u897f \u5e72\u4ec0\u4e48\u7528 \u5199\u6cd5 on_frame \u6bcf\u5e27\u56de\u8c03\uff0c\u8bad\u7ec3 + \u66f4\u65b0\u5728\u8fd9\u91cc\u641e <code>@view.on_frame</code> create_tensor \u521b\u5efa GPU \u5171\u4eab\u663e\u5b58 tensor <code>vultorch.create_tensor(H, W, ...)</code> <p>\u56de\u8c03\u51fd\u6570\u91cc\u968f\u4fbf\u5199 PyTorch \u4ee3\u7801\uff0cVultorch \u6bcf\u5e27\u5e2e\u4f60\u628a tensor \u642c\u4e0a\u5c4f\u5e55\u3002</p>"},{"location":"zh/03_training_test/#_3","title":"\u5b8c\u6574\u4ee3\u7801","text":"<pre><code>from pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport vultorch\nui = vultorch.ui\n\ntry:\n    from PIL import Image\nexcept ImportError as exc:\n    raise RuntimeError(\"Please install pillow: pip install pillow\") from exc\n\n\nclass TinyMLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(2, 64),\n            nn.ReLU(inplace=True),\n            nn.Linear(64, 64),\n            nn.ReLU(inplace=True),\n            nn.Linear(64, 3),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nif not torch.cuda.is_available():\n    raise RuntimeError(\"This example needs CUDA\")\n\ndevice = \"cuda\"\n\n# \u52a0\u8f7d\u76ee\u6807\u56fe\nimg_path = Path(__file__).resolve().parents[1] / \"docs\" / \"images\" / \"pytorch_logo.png\"\nimg = Image.open(img_path).convert(\"RGB\").resize((256, 256), Image.BILINEAR)\ngt = torch.from_numpy(np.asarray(img, dtype=np.float32) / 255.0).to(device)\n\nH, W = gt.shape[0], gt.shape[1]\nys = torch.linspace(-1.0, 1.0, H, device=device)\nxs = torch.linspace(-1.0, 1.0, W, device=device)\nyy, xx = torch.meshgrid(ys, xs, indexing=\"ij\")\ncoords = torch.stack([xx, yy], dim=-1).reshape(-1, 2)  # (H*W, 2)\ntarget = gt.reshape(-1, 3)                               # (H*W, 3)\n\nmodel = TinyMLP().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n\nview = vultorch.View(\"03 - Training Test\", 1280, 760)\ngt_panel = view.panel(\"GT\")\npred_panel = view.panel(\"Prediction\")\n\ngt_panel.canvas(\"gt\").bind(gt)\n\n# \u9884\u6d4b\u7528 4 \u901a\u9053 \u2014 GPU \u96f6\u62f7\u8d1d\u663e\u793a\npred_rgba = vultorch.create_tensor(H, W, channels=4, device=device,\n                                   name=\"pred\", window=view.window)\npred_rgba[:, :, 3] = 1.0\npred_panel.canvas(\"pred\").bind(pred_rgba)\n\nstate = {\n    \"iter\": 0,\n    \"loss\": 1.0,\n    \"ema\": 1.0,\n    \"steps_per_frame\": 6,\n    \"layout_done\": False,\n}\n\n\n@view.on_frame\ndef train_and_render():\n    # ---- \u9996\u5e27\u624b\u52a8\u5e03\u5c40\uff1a\u4e0a\u9762\u5de6\u53f3\u5206\uff0c\u4e0b\u9762\u653e Info ----\n    if not state[\"layout_done\"]:\n        dockspace_id = ui.dock_space_over_viewport(flags=8)\n        ui.dock_builder_remove_node(dockspace_id)\n        ui.dock_builder_add_node(dockspace_id, 1 &lt;&lt; 10)\n        ui.dock_builder_set_node_size(dockspace_id, 1280.0, 760.0)\n\n        info_node, top_node = ui.dock_builder_split_node(dockspace_id, 3, 0.28)\n        left_node, right_node = ui.dock_builder_split_node(top_node, 0, 0.5)\n\n        ui.dock_builder_dock_window(\"GT\", left_node)\n        ui.dock_builder_dock_window(\"Prediction\", right_node)\n        ui.dock_builder_dock_window(\"Info\", info_node)\n        ui.dock_builder_finish(dockspace_id)\n        state[\"layout_done\"] = True\n\n    # ---- \u8bad\u7ec3\u51e0\u6b65 ----\n    for _ in range(state[\"steps_per_frame\"]):\n        optimizer.zero_grad(set_to_none=True)\n        out = model(coords)\n        loss = F.mse_loss(out, target)\n        loss.backward()\n        optimizer.step()\n\n        state[\"iter\"] += 1\n        state[\"loss\"] = loss.item()\n        state[\"ema\"] = state[\"ema\"] * 0.98 + state[\"loss\"] * 0.02\n\n    # ---- \u628a\u9884\u6d4b\u5199\u8fdb\u663e\u793a tensor ----\n    with torch.no_grad():\n        pred = model(coords).reshape(H, W, 3).clamp_(0, 1)\n        pred_rgba[:, :, :3] = pred\n\n    # ---- Info \u9762\u677f ----\n    ui.begin(\"Info\", True, 0)\n    ui.text(f\"FPS: {view.fps:.1f}\")\n    ui.text(f\"Iteration: {state['iter']}\")\n    ui.text(f\"Loss (MSE): {state['loss']:.6f}\")\n    ui.text(f\"EMA Loss: {state['ema']:.6f}\")\n\n    state[\"steps_per_frame\"] = ui.slider_int(\n        \"Steps / Frame\", state[\"steps_per_frame\"], 1, 32\n    )\n    progress = min(1.0, state[\"iter\"] / 3000.0)\n    ui.progress_bar(progress, overlay=f\"Training progress {progress * 100:.1f}%\")\n    ui.text_wrapped(\n        \"\u5de6\u8fb9\u662f GT\uff0c\u53f3\u8fb9\u662f\u9884\u6d4b\u3002\u60f3\u66f4\u5feb\u6536\u655b\u5c31\u63d0\u9ad8 Steps / Frame\u3002\"\n    )\n    ui.end()\n\n\nview.run()\n</code></pre> <p>\u641e\u5b9a\u3002\u8dd1\u8d77\u6765\u4e4b\u540e\u4f60\u4f1a\u770b\u5230\u53f3\u8fb9\u90a3\u5768\u7070\u8272\u5728\u51e0\u79d2\u5185\u53d8\u6210 PyTorch logo\u3002</p>"},{"location":"zh/03_training_test/#_4","title":"\u521a\u624d\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f","text":"<ol> <li> <p>\u6570\u636e \u2014 PIL \u8bfb\u56fe\uff0c\u8f6c\u6210 float32 CUDA tensor \u5f53 GT\u3002    \u5750\u6807\u7528 <code>meshgrid</code> \u5c55\u6210 <code>(H*W, 2)</code>\uff0c\u6bcf\u4e2a\u50cf\u7d20\u7684 <code>(x, y)</code> \u5f52\u4e00\u5316\u5230 <code>[-1, 1]</code>\u3002</p> </li> <li> <p>\u6a21\u578b \u2014 \u4e24\u5c42 64 \u5bbd\u7684 MLP\uff0c\u8f93\u5165 <code>(x, y)</code>\uff0c\u8f93\u51fa <code>(r, g, b)</code>\u3002    \u8fd9\u4e2a\u7f51\u7edc\u5c0f\u5230\u53ef\u4ee5\u8dd1\u5728\u56de\u8c03\u91cc\u4e0d\u6389\u5e27\u3002</p> </li> <li> <p>on_frame \u56de\u8c03 \u2014 \u6bcf\u5e27\u8c03\u7528\u4e00\u6b21\u3002\u91cc\u9762\u505a\u4e86\u4e09\u4ef6\u4e8b\uff1a    \u9996\u5e27\u641e\u5b9a\u5e03\u5c40\uff0c\u7136\u540e\u8dd1 N \u6b65\u8bad\u7ec3\uff0c\u6700\u540e\u628a\u9884\u6d4b\u5199\u56de <code>pred_rgba</code>\u3002</p> </li> <li> <p>Info \u9762\u677f \u2014 \u7528 ImGui \u7684 <code>ui.begin()</code> / <code>ui.end()</code> \u624b\u52a8\u753b\u4e86\u7b2c\u4e09\u4e2a\u9762\u677f\u3002    \u53ef\u4ee5\u653e\u6587\u5b57\u3001\u6ed1\u6761\u3001\u8fdb\u5ea6\u6761 \u2014\u2014 \u4ec0\u4e48 widget \u90fd\u884c\u3002</p> </li> </ol>"},{"location":"zh/03_training_test/#_5","title":"\u8981\u70b9","text":"<ol> <li> <p><code>@view.on_frame</code> \u2014 \u56de\u8c03\u91cc\u53ef\u4ee5\u8dd1\u4efb\u610f PyTorch \u4ee3\u7801\u3002    \u6bcf\u5e27\u7ed3\u675f\u65f6 Vultorch \u81ea\u52a8\u628a\u7ed1\u5b9a\u7684 tensor \u642c\u5230\u5c4f\u5e55\uff0c\u4e0d\u7528\u4f60\u7ba1\u3002</p> </li> <li> <p><code>create_tensor</code> \u2014 \u8ddf\u666e\u901a <code>torch.zeros</code> \u4e00\u6837\u7528\uff0c    \u4f46\u5e95\u5c42\u662f Vulkan/CUDA \u5171\u4eab\u663e\u5b58\uff0c\u663e\u793a\u7684\u65f6\u5019\u96f6\u62f7\u8d1d\u3002</p> </li> <li> <p>\u624b\u52a8\u5e03\u5c40 \u2014 <code>dock_builder_split_node</code> \u53ef\u4ee5\u628a\u7a97\u53e3\u5207\u6210\u4efb\u610f\u4f60\u60f3\u8981\u7684\u6837\u5b50\u3002    \u65b9\u5411\uff1a<code>0=\u5de6, 1=\u53f3, 2=\u4e0a, 3=\u4e0b</code>\uff0c\u6bd4\u4f8b\u7528 float\u3002</p> </li> <li> <p>\u4e0d\u5237\u7ec8\u7aef \u2014 \u6240\u6709\u72b6\u6001\u4fe1\u606f\u90fd\u5728 Info \u9762\u677f\u91cc\uff0c    \u4f60\u7684\u7ec8\u7aef\u53ef\u4ee5\u7559\u7740\u770b warning \u548c traceback\uff0c\u5e72\u51c0\u591a\u4e86\u3002</p> </li> </ol> <p>\u63d0\u793a</p> <p><code>Steps / Frame</code> \u6ed1\u6761\u62c9\u5230 32 \u6536\u655b\u98de\u5feb\u3002 \u4f46\u4e5f\u522b\u592a\u8d2a \u2014\u2014 \u62c9\u592a\u9ad8\u5e27\u7387\u4f1a\u6389\u4e0b\u6765\uff0c\u56e0\u4e3a\u6bcf\u5e27\u7684\u8bad\u7ec3\u65f6\u95f4\u53d8\u957f\u4e86\u3002</p> <p>\u8bf4\u660e</p> <p><code>create_tensor</code> \u53ea\u5728\u521d\u59cb\u5316\u65f6\u8c03\u7528\u4e00\u6b21\uff0c\u4e0d\u5728\u5e27\u5faa\u73af\u91cc\u3002 \u4e4b\u540e\u6bcf\u5e27\u53ea\u9700\u8981\u5f80\u8fd9\u4e2a tensor \u91cc\u5199\u6570\u636e\uff0c\u5f00\u9500\u51e0\u4e4e\u4e3a\u96f6\u3002</p>"},{"location":"zh/api/","title":"API \u53c2\u8003\u6587\u6863","text":"<p><code>vultorch</code> \u5305\u6240\u6709\u516c\u5f00\u7c7b\u548c\u51fd\u6570\u7684\u5b8c\u6574\u53c2\u8003\u3002</p>"},{"location":"zh/api/#_1","title":"\u6a21\u5757\u7ea7\u5c5e\u6027","text":""},{"location":"zh/api/#vultorch__version__","title":"<code>vultorch.__version__</code>","text":"<pre><code>__version__: str\n</code></pre> <p>\u5305\u7248\u672c\u5b57\u7b26\u4e32\uff08\u4f8b\u5982 <code>\"0.5.0\"</code>\uff09\u3002</p>"},{"location":"zh/api/#vultorchhas_cuda","title":"<code>vultorch.HAS_CUDA</code>","text":"<pre><code>HAS_CUDA: bool\n</code></pre> <p>\u5982\u679c\u539f\u751f\u6269\u5c55\u6a21\u5757\u7f16\u8bd1\u65f6\u542f\u7528\u4e86 CUDA \u5219\u4e3a <code>True</code>\u3002\u4e3a <code>False</code> \u65f6\uff0c\u6240\u6709\u5f20\u91cf\u663e\u793a\u5c06\u56de\u9000\u5230 CPU \u6682\u5b58\u7f13\u51b2\u533a\uff08host-visible <code>memcpy</code>\uff09\u3002</p>"},{"location":"zh/api/#_2","title":"\u6838\u5fc3\u51fd\u6570","text":""},{"location":"zh/api/#vultorchshow","title":"<code>vultorch.show()</code>","text":"<pre><code>def show(\n    tensor: torch.Tensor,\n    *,\n    name: str = \"tensor\",\n    width: float = 0,\n    height: float = 0,\n    filter: str = \"linear\",\n    window: Window | None = None,\n) -&gt; None\n</code></pre> <p>\u5728\u5f53\u524d ImGui \u4e0a\u4e0b\u6587\u4e2d\u663e\u793a\u5f20\u91cf\u3002</p> <p>\u53c2\u6570\uff1a</p> \u53c2\u6570 \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 <code>tensor</code> <code>torch.Tensor</code> (\u5fc5\u9700) CUDA \u6216 CPU \u5f20\u91cf\u3002dtype\uff1a<code>float32</code>\u3001<code>float16</code> \u6216 <code>uint8</code>\u3002\u5f62\u72b6\uff1a<code>(H, W)</code> \u6216 <code>(H, W, C)</code>\uff0cC \u2208 {1, 3, 4}\u3002 <code>name</code> <code>str</code> <code>\"tensor\"</code> \u552f\u4e00\u6807\u7b7e\uff0c\u7528\u4e8e\u540c\u65f6\u663e\u793a\u591a\u4e2a\u5f20\u91cf\u65f6\u7684\u7f13\u5b58\u3002 <code>width</code> <code>float</code> <code>0</code> \u663e\u793a\u5bbd\u5ea6\uff08\u50cf\u7d20\uff09\u3002<code>0</code> = \u81ea\u52a8\u9002\u5e94\u5f20\u91cf\u5927\u5c0f\u3002 <code>height</code> <code>float</code> <code>0</code> \u663e\u793a\u9ad8\u5ea6\uff08\u50cf\u7d20\uff09\u3002<code>0</code> = \u81ea\u52a8\u9002\u5e94\u5f20\u91cf\u5927\u5c0f\u3002 <code>filter</code> <code>str</code> <code>\"linear\"</code> \u91c7\u6837\u6ee4\u6ce2\u5668\uff1a<code>\"nearest\"</code> \u6216 <code>\"linear\"</code>\u3002 <code>window</code> <code>Window \\| None</code> <code>None</code> \u76ee\u6807\u7a97\u53e3\u3002\u9ed8\u8ba4\u4f7f\u7528 <code>Window._current</code>\u3002 <p>\u884c\u4e3a\uff1a</p> <ul> <li>1 \u901a\u9053\u548c 3 \u901a\u9053\u5f20\u91cf\u4f1a\u81ea\u52a8\u6269\u5c55\u4e3a RGBA\u3002</li> <li>RGBA \u6269\u5c55\u7f13\u51b2\u533a\u6309 <code>name</code> \u7f13\u5b58\uff0c\u907f\u514d\u6bcf\u5e27\u5206\u914d\u5185\u5b58\u3002</li> <li>CUDA\uff1a\u4f7f\u7528\u96f6\u62f7\u8d1d GPU\u2192GPU \u8def\u5f84\u3002CPU\uff1a\u4f7f\u7528 host-visible \u6682\u5b58\u7f13\u51b2\u533a\u3002</li> <li><code>uint8</code> \u5f20\u91cf\u9664\u4ee5 255\uff1b<code>float16</code> \u5f20\u91cf\u8f6c\u6362\u4e3a <code>float32</code>\u3002</li> </ul> <p>\u5f02\u5e38\uff1a \u5982\u679c\u6ca1\u6709\u6d3b\u8dc3\u7684 <code>Window</code> \u5219\u629b\u51fa <code>RuntimeError</code>\u3002</p>"},{"location":"zh/api/#vultorchcreate_tensor","title":"<code>vultorch.create_tensor()</code>","text":"<pre><code>def create_tensor(\n    height: int,\n    width: int,\n    channels: int = 4,\n    device: str = \"cuda:0\",\n    *,\n    name: str = \"tensor\",\n    window: Window | None = None,\n) -&gt; torch.Tensor\n</code></pre> <p>\u5206\u914d Vulkan \u5171\u4eab\u7684 CUDA \u5f20\u91cf\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u96f6\u62f7\u8d1d\u663e\u793a\u3002</p> <p>\u53c2\u6570\uff1a</p> \u53c2\u6570 \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 <code>height</code> <code>int</code> (\u5fc5\u9700) \u5f20\u91cf\u9ad8\u5ea6\uff08\u50cf\u7d20\uff09\u3002 <code>width</code> <code>int</code> (\u5fc5\u9700) \u5f20\u91cf\u5bbd\u5ea6\uff08\u50cf\u7d20\uff09\u3002 <code>channels</code> <code>int</code> <code>4</code> \u901a\u9053\u6570\uff1a1\u30013 \u6216 4\u3002 <code>device</code> <code>str</code> <code>\"cuda:0\"</code> CUDA \u8bbe\u5907\u5b57\u7b26\u4e32\uff0c\u6216 <code>\"cpu\"</code>\u3002 <code>name</code> <code>str</code> <code>\"tensor\"</code> \u7eb9\u7406\u69fd\u540d\u79f0\uff08\u5fc5\u987b\u4e0e <code>show(..., name=...)</code> \u5339\u914d\uff09\u3002 <code>window</code> <code>Window \\| None</code> <code>None</code> \u76ee\u6807\u7a97\u53e3\u3002\u9ed8\u8ba4\u4f7f\u7528 <code>Window._current</code>\u3002 <p>\u8fd4\u56de\uff1a \u5f62\u72b6\u4e3a <code>(height, width, channels)</code> \u7684 <code>torch.Tensor</code>\u3002</p> <p>Note</p> <p>\u53ea\u6709 <code>channels=4</code> \u624d\u80fd\u901a\u8fc7 Vulkan \u5916\u90e8\u5185\u5b58\u5b9e\u73b0\u771f\u6b63\u7684\u96f6\u62f7\u8d1d\u3002\u5bf9\u4e8e 1 \u6216 3 \u901a\u9053\uff0c\u8fd4\u56de\u666e\u901a CUDA \u5f20\u91cf\uff0c<code>show()</code> \u4f1a\u5904\u7406 RGBA \u6269\u5c55\u5e76\u8fdb\u884c GPU\u2192GPU \u62f7\u8d1d\u3002</p> <p>\u5f02\u5e38\uff1a \u5982\u679c\u6ca1\u6709\u6d3b\u8dc3\u7684 <code>Window</code> \u5219\u629b\u51fa <code>RuntimeError</code>\u3002</p>"},{"location":"zh/api/#_3","title":"\u7c7b","text":""},{"location":"zh/api/#vultorchwindow","title":"<code>vultorch.Window</code>","text":"<pre><code>class Window:\n    _current: Window | None   # \u5355\u4f8b\u5f15\u7528\n\n    def __init__(self, title: str = \"Vultorch\",\n                 width: int = 1280, height: int = 720) -&gt; None: ...\n</code></pre> <p>Vulkan + SDL3 + ImGui \u5f15\u64ce\u7684\u9ad8\u5c42\u5c01\u88c5\u3002\u521b\u5efa <code>Window</code> \u4f1a\u81ea\u52a8\u5c06\u5176\u8bbe\u7f6e\u4e3a <code>show()</code> \u548c <code>create_tensor()</code> \u7684\u5f53\u524d\u76ee\u6807\u3002</p>"},{"location":"zh/api/#_4","title":"\u65b9\u6cd5","text":"\u65b9\u6cd5 \u7b7e\u540d \u63cf\u8ff0 <code>poll()</code> <code>\u2192 bool</code> \u5904\u7406\u64cd\u4f5c\u7cfb\u7edf\u4e8b\u4ef6\u3002\u7a97\u53e3\u5e94\u5173\u95ed\u65f6\u8fd4\u56de <code>False</code>\u3002 <code>begin_frame()</code> <code>\u2192 bool</code> \u5f00\u59cb\u65b0\u7684 ImGui \u5e27\u3002\u5e27\u88ab\u8df3\u8fc7\uff08\u6700\u5c0f\u5316\uff09\u65f6\u8fd4\u56de <code>False</code>\u3002 <code>end_frame()</code> <code>\u2192 None</code> \u63d0\u4ea4\u5e27\u5230 GPU \u5e76\u5448\u73b0\u3002 <code>activate()</code> <code>\u2192 None</code> \u5c06\u6b64\u7a97\u53e3\u8bbe\u4e3a\u6a21\u5757\u7ea7\u8f85\u52a9\u51fd\u6570\u7684\u5f53\u524d\u76ee\u6807\u3002 <code>upload_tensor(tensor, *, name)</code> <code>\u2192 None</code> \u4e0a\u4f20\u5f20\u91cf\u7528\u4e8e\u663e\u793a\uff08CUDA \u6216 CPU\uff09\u3002 <code>get_texture_id(name)</code> <code>\u2192 int</code> \u6307\u5b9a\u540d\u79f0\u5f20\u91cf\u7684 ImGui \u7eb9\u7406 ID\u3002 <code>get_texture_size(name)</code> <code>\u2192 (int, int)</code> \u6307\u5b9a\u540d\u79f0\u5f20\u91cf\u7684 <code>(\u5bbd\u5ea6, \u9ad8\u5ea6)</code>\u3002 <code>destroy()</code> <code>\u2192 None</code> \u91ca\u653e\u6240\u6709 GPU / \u7a97\u53e3\u8d44\u6e90\u3002\u53ef\u5b89\u5168\u591a\u6b21\u8c03\u7528\u3002"},{"location":"zh/api/#_5","title":"\u5c5e\u6027","text":"\u5c5e\u6027 \u7c7b\u578b \u63cf\u8ff0 <code>tensor_texture_id</code> <code>int</code> \u9ed8\u8ba4 <code>\"tensor\"</code> \u69fd\u7684 ImGui \u7eb9\u7406 ID\u3002 <code>tensor_size</code> <code>(int, int)</code> \u9ed8\u8ba4 <code>\"tensor\"</code> \u69fd\u7684 <code>(\u5bbd\u5ea6, \u9ad8\u5ea6)</code>\u3002"},{"location":"zh/api/#_6","title":"\u4f7f\u7528\u793a\u4f8b","text":"<pre><code>import vultorch\nfrom vultorch import ui\n\nwin = vultorch.Window(\"Demo\", 1280, 720)\nwhile win.poll():\n    if not win.begin_frame():\n        continue\n    ui.begin(\"Panel\", True, 0)\n    vultorch.show(tensor)\n    ui.end()\n    win.end_frame()\nwin.destroy()\n</code></pre>"},{"location":"zh/api/#vultorchcamera","title":"<code>vultorch.Camera</code>","text":"<pre><code>class Camera:\n    azimuth: float     # \u6c34\u5e73\u89d2\u5ea6\uff08\u5f27\u5ea6\uff09\uff0c\u9ed8\u8ba4 0.0\n    elevation: float   # \u5782\u76f4\u89d2\u5ea6\uff08\u5f27\u5ea6\uff09\uff0c\u9ed8\u8ba4 0.6\n    distance: float    # \u5230\u76ee\u6807\u7684\u8ddd\u79bb\uff0c\u9ed8\u8ba4 3.0\n    target: tuple      # (x, y, z) \u6ce8\u89c6\u70b9\uff0c\u9ed8\u8ba4 (0, 0, 0)\n    fov: float         # \u89c6\u573a\u89d2\uff08\u5ea6\uff09\uff0c\u9ed8\u8ba4 45.0\n</code></pre> <p><code>SceneView</code> \u4f7f\u7528\u7684\u8f68\u9053\u76f8\u673a\u53c2\u6570\u3002\u8c03\u7528 <code>reset()</code> \u6062\u590d\u9ed8\u8ba4\u503c\u3002</p>"},{"location":"zh/api/#vultorchlight","title":"<code>vultorch.Light</code>","text":"<pre><code>class Light:\n    direction: tuple   # (x, y, z)\uff0c\u9ed8\u8ba4 (0.3, -1.0, 0.5)\n    color: tuple       # (r, g, b)\uff0c\u9ed8\u8ba4 (1, 1, 1)\n    intensity: float   # \u9ed8\u8ba4 1.0\n    ambient: float     # \u73af\u5883\u5149\u9879\uff0c\u9ed8\u8ba4 0.15\n    specular: float    # \u9ad8\u5149\u9879\uff0c\u9ed8\u8ba4 0.5\n    shininess: float   # Blinn-Phong \u6307\u6570\uff0c\u9ed8\u8ba4 32.0\n    enabled: bool      # \u9ed8\u8ba4 True\n</code></pre> <p><code>SceneView</code> \u4f7f\u7528\u7684 Blinn-Phong \u65b9\u5411\u5149\u53c2\u6570\u3002</p>"},{"location":"zh/api/#vultorchsceneview","title":"<code>vultorch.SceneView</code>","text":"<pre><code>class SceneView:\n    def __init__(self, name: str = \"SceneView\",\n                 width: int = 800, height: int = 600,\n                 msaa: int = 4) -&gt; None: ...\n</code></pre> <p>3D \u5f20\u91cf\u67e5\u770b\u5668 \u2014 \u5728\u5e26\u5149\u7167\u7684\u5e73\u9762\u4e0a\u6e32\u67d3\u5f20\u91cf\uff0c\u652f\u6301\u8f68\u9053\u76f8\u673a\u548c MSAA\u3002</p>"},{"location":"zh/api/#_7","title":"\u5c5e\u6027","text":"\u5c5e\u6027 \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 <code>name</code> <code>str</code> <code>\"SceneView\"</code> ImGui \u7a97\u53e3\u6807\u7b7e\u3002 <code>camera</code> <code>Camera</code> (\u81ea\u52a8) \u8f68\u9053\u76f8\u673a\uff08\u62d6\u62fd\u65cb\u8f6c\uff09\u3002 <code>light</code> <code>Light</code> (\u81ea\u52a8) \u65b9\u5411\u5149\u6e90\u3002 <code>background</code> <code>tuple</code> <code>(0.12, 0.12, 0.14)</code> \u80cc\u666f\u989c\u8272 <code>(r, g, b)</code>\u3002 <code>msaa</code> <code>int</code> <code>4</code> \u591a\u91cd\u91c7\u6837\u6297\u952f\u9f7f\u7ea7\u522b\uff081/2/4/8\uff09\u3002"},{"location":"zh/api/#_8","title":"\u65b9\u6cd5","text":"\u65b9\u6cd5 \u63cf\u8ff0 <code>set_tensor(tensor)</code> \u4e0a\u4f20\u5f20\u91cf\u5230\u573a\u666f\u7eb9\u7406\u3002 <code>render()</code> \u5904\u7406\u9f20\u6807\u4ea4\u4e92\uff0c\u6e32\u67d3\u573a\u666f\uff0c\u5e76\u4f5c\u4e3a ImGui \u56fe\u50cf\u663e\u793a\u3002"},{"location":"zh/api/#_9","title":"\u4f7f\u7528\u793a\u4f8b","text":"<pre><code>scene = vultorch.SceneView(\"3D \u89c6\u56fe\", 800, 600, msaa=4)\n# \u5728\u5e27\u5faa\u73af\u4e2d\uff1a\nscene.set_tensor(tensor)\nscene.render()\n</code></pre>"},{"location":"zh/api/#api_1","title":"\u58f0\u660e\u5f0f API","text":"<p>\u58f0\u660e\u5f0f API \u63d0\u4f9b\u4e86\u66f4\u9ad8\u5c42\u7684\u62bd\u8c61\uff0c\u7528\u4e8e\u6784\u5efa\u591a\u9762\u677f\u53ef\u89c6\u5316\u5e94\u7528\u3002</p>"},{"location":"zh/api/#vultorchview","title":"<code>vultorch.View</code>","text":"<pre><code>class View:\n    def __init__(self, title: str = \"Vultorch\",\n                 width: int = 1280, height: int = 720) -&gt; None: ...\n</code></pre> <p>\u652f\u6301\u81ea\u52a8\u505c\u9760\u5e03\u5c40\u7684\u9876\u5c42\u7a97\u53e3\u3002</p>"},{"location":"zh/api/#_10","title":"\u65b9\u6cd5","text":"\u65b9\u6cd5 \u7b7e\u540d \u63cf\u8ff0 <code>panel(name, *, side, width)</code> <code>\u2192 Panel</code> \u521b\u5efa\u6216\u83b7\u53d6\u53ef\u505c\u9760\u9762\u677f\u3002<code>side</code>\uff1a<code>\"left\"</code> / <code>\"right\"</code> / <code>None</code>\u3002 <code>on_frame(fn)</code> <code>\u2192 fn</code> \u88c5\u9970\u5668 \u2014 \u6ce8\u518c\u6bcf\u5e27\u56de\u8c03\u51fd\u6570\u3002 <code>run()</code> <code>\u2192 None</code> \u963b\u585e\u5f0f\u4e8b\u4ef6\u5faa\u73af\u3002 <code>step()</code> <code>\u2192 bool</code> \u975e\u963b\u585e\uff1a\u5904\u7406\u4e00\u5e27\u3002\u5173\u95ed\u65f6\u8fd4\u56de <code>False</code>\u3002 <code>end_step()</code> <code>\u2192 None</code> \u7ed3\u675f\u7531 <code>step()</code> \u5f00\u59cb\u7684\u5e27\u3002 <code>close()</code> <code>\u2192 None</code> \u9500\u6bc1\u7a97\u53e3\u3002"},{"location":"zh/api/#_11","title":"\u5c5e\u6027","text":"\u5c5e\u6027 \u7c7b\u578b \u63cf\u8ff0 <code>fps</code> <code>float</code> \u5f53\u524d\u6bcf\u79d2\u5e27\u6570\u3002 <code>time</code> <code>float</code> \u5df2\u8fc7\u79d2\u6570\u3002 <code>window</code> <code>Window</code> \u5e95\u5c42 <code>Window</code> \u5b9e\u4f8b\u3002"},{"location":"zh/api/#_12","title":"\u4f7f\u7528\u793a\u4f8b \u2014 \u963b\u585e\u6a21\u5f0f","text":"<pre><code>view = vultorch.View(\"Demo\", 1280, 720)\nview.panel(\"Viewer\").canvas(\"img\").bind(tensor)\n\n@view.on_frame\ndef update():\n    speed = controls.slider(\"Speed\", 0, 10)\n    tensor[:,:,0] = (x + view.time * speed).sin()\n\nview.run()\n</code></pre>"},{"location":"zh/api/#_13","title":"\u4f7f\u7528\u793a\u4f8b \u2014 \u8bad\u7ec3\u5faa\u73af","text":"<pre><code>view = vultorch.View(\"Train\", 1024, 768)\noutput = view.panel(\"Output\").canvas(\"result\")\nfor epoch in range(100):\n    result = model(input)\n    output.bind(result)\n    if not view.step():\n        break\n    view.end_step()\nview.close()\n</code></pre>"},{"location":"zh/api/#vultorchpanel","title":"<code>vultorch.Panel</code>","text":"<pre><code>class Panel:\n    # \u901a\u8fc7 View.panel() \u521b\u5efa \u2014 \u4e0d\u76f4\u63a5\u5b9e\u4f8b\u5316\n</code></pre> <p>\u5305\u542b\u753b\u5e03\u548c\u63a7\u4ef6\u7684\u53ef\u505c\u9760\u9762\u677f\u3002</p>"},{"location":"zh/api/#_14","title":"\u753b\u5e03\u5de5\u5382","text":"\u65b9\u6cd5 \u7b7e\u540d \u63cf\u8ff0 <code>canvas(name, *, filter, fit)</code> <code>\u2192 Canvas</code> \u521b\u5efa\u547d\u540d\u753b\u5e03\u3002<code>filter</code>\uff1a<code>\"linear\"</code> / <code>\"nearest\"</code>\u3002<code>fit</code>\uff1a\u81ea\u52a8\u586b\u5145\u9762\u677f\u7a7a\u95f4\u3002"},{"location":"zh/api/#_15","title":"\u5e03\u5c40","text":"\u65b9\u6cd5 \u63cf\u8ff0 <code>row()</code> \u4e0a\u4e0b\u6587\u7ba1\u7406\u5668 \u2014 \u5c06\u5b50\u63a7\u4ef6\u5e76\u6392\u653e\u7f6e\u3002"},{"location":"zh/api/#_16","title":"\u63a7\u4ef6","text":"<p>\u6240\u6709\u63a7\u4ef6\u65b9\u6cd5\u81ea\u52a8\u7ba1\u7406\u8de8\u5e27\u72b6\u6001\u3002</p> \u65b9\u6cd5 \u7b7e\u540d \u63cf\u8ff0 <code>text(text)</code> <code>\u2192 None</code> \u9759\u6001\u6587\u672c\u3002 <code>text_colored(r, g, b, a, text)</code> <code>\u2192 None</code> \u6709\u989c\u8272\u7684\u6587\u672c\u3002 <code>text_wrapped(text)</code> <code>\u2192 None</code> \u81ea\u52a8\u6362\u884c\u6587\u672c\u3002 <code>separator()</code> <code>\u2192 None</code> \u6c34\u5e73\u5206\u9694\u7ebf\u3002 <code>button(label)</code> <code>\u2192 bool</code> \u6309\u94ae\u3002\u70b9\u51fb\u65f6\u8fd4\u56de <code>True</code>\u3002 <code>checkbox(label, *, default)</code> <code>\u2192 bool</code> \u5e26\u72b6\u6001\u5207\u6362\u7684\u590d\u9009\u6846\u3002 <code>slider(label, min, max, *, default)</code> <code>\u2192 float</code> \u6d6e\u70b9\u6ed1\u5757\u3002 <code>slider_int(label, min, max, *, default)</code> <code>\u2192 int</code> \u6574\u6570\u6ed1\u5757\u3002 <code>color_picker(label, *, default)</code> <code>\u2192 (r, g, b)</code> \u989c\u8272\u9009\u62e9\u5668\uff083 \u6d6e\u70b9\u5143\u7ec4\uff09\u3002 <code>combo(label, items, *, default)</code> <code>\u2192 int</code> \u4e0b\u62c9\u7ec4\u5408\u6846\u3002\u8fd4\u56de\u9009\u4e2d\u7d22\u5f15\u3002 <code>input_text(label, *, default, max_length)</code> <code>\u2192 str</code> \u6587\u672c\u8f93\u5165\u6846\u3002 <code>plot(values, *, label, overlay, width, height)</code> <code>\u2192 None</code> \u6d6e\u70b9\u5217\u8868\u7684\u6298\u7ebf\u56fe\u3002 <code>progress(fraction, *, overlay)</code> <code>\u2192 None</code> \u8fdb\u5ea6\u6761\uff080.0 \u2013 1.0\uff09\u3002"},{"location":"zh/api/#vultorchcanvas","title":"<code>vultorch.Canvas</code>","text":"<pre><code>class Canvas:\n    # \u901a\u8fc7 Panel.canvas() \u521b\u5efa \u2014 \u4e0d\u76f4\u63a5\u5b9e\u4f8b\u5316\n</code></pre> <p>\u5c06\u7ed1\u5b9a\u5f20\u91cf\u6e32\u67d3\u4e3a ImGui \u56fe\u50cf\u7684\u663e\u793a\u8868\u9762\u3002</p>"},{"location":"zh/api/#_17","title":"\u65b9\u6cd5","text":"\u65b9\u6cd5 \u7b7e\u540d \u63cf\u8ff0 <code>bind(tensor)</code> <code>\u2192 Canvas</code> \u7ed1\u5b9a\u5f20\u91cf\u7528\u4e8e\u663e\u793a\u3002\u8fd4\u56de <code>self</code> \u4ee5\u652f\u6301\u94fe\u5f0f\u8c03\u7528\u3002 <code>alloc(height, width, channels, device)</code> <code>\u2192 torch.Tensor</code> \u5206\u914d Vulkan \u5171\u4eab\u5185\u5b58\u5e76\u81ea\u52a8\u7ed1\u5b9a\u3002\u8fd4\u56de\u5f20\u91cf\u3002"},{"location":"zh/api/#_18","title":"\u5c5e\u6027","text":"\u5c5e\u6027 \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 <code>filter</code> <code>str</code> <code>\"linear\"</code> <code>\"linear\"</code> \u6216 <code>\"nearest\"</code>\u3002 <code>fit</code> <code>bool</code> <code>True</code> \u81ea\u52a8\u586b\u5145\u53ef\u7528\u9762\u677f\u7a7a\u95f4\u3002"},{"location":"zh/api/#imgui-vultorchui","title":"ImGui \u7ed1\u5b9a (<code>vultorch.ui</code>)","text":"<p><code>vultorch.ui</code> \u5b50\u6a21\u5757\u66b4\u9732\u4e86 Dear ImGui \u51fd\u6570\uff08docking \u5206\u652f\uff09\u3002\u6240\u6709\u51fd\u6570\u76f4\u63a5\u6620\u5c04\u5230\u5bf9\u5e94\u7684 ImGui C++ \u63a5\u53e3\u3002</p>"},{"location":"zh/api/#_19","title":"\u7a97\u53e3","text":"<pre><code>ui.begin(name: str, opened: bool = True, flags: int = 0) -&gt; tuple[bool, bool]\nui.end() -&gt; None\nui.begin_child(id: str, width=0.0, height=0.0, child_flags=0, window_flags=0) -&gt; bool\nui.end_child() -&gt; None\n</code></pre>"},{"location":"zh/api/#_20","title":"\u6587\u672c","text":"<pre><code>ui.text(text: str) -&gt; None\nui.text_colored(r, g, b, a, text: str) -&gt; None\nui.text_disabled(text: str) -&gt; None\nui.text_wrapped(text: str) -&gt; None\nui.label_text(label: str, text: str) -&gt; None\nui.bullet_text(text: str) -&gt; None\n</code></pre>"},{"location":"zh/api/#_21","title":"\u6309\u94ae","text":"<pre><code>ui.button(label: str, width=0.0, height=0.0) -&gt; bool\nui.small_button(label: str) -&gt; bool\nui.invisible_button(id: str, width, height) -&gt; bool\nui.arrow_button(id: str, direction: int) -&gt; bool\nui.radio_button(label: str, active: bool) -&gt; bool\n</code></pre>"},{"location":"zh/api/#_22","title":"\u8f93\u5165","text":"<pre><code>ui.checkbox(label, value: bool) -&gt; bool\nui.slider_float(label, value, min=0.0, max=1.0, format=\"%.3f\") -&gt; float\nui.slider_float2(label, v1, v2, min, max) -&gt; tuple[float, float]\nui.slider_float3(label, v1, v2, v3, min, max) -&gt; tuple[float, float, float]\nui.slider_float4(label, v1, v2, v3, v4, min, max) -&gt; tuple\nui.slider_int(label, value, min=0, max=100) -&gt; int\nui.slider_angle(label, value, min=-360, max=360) -&gt; float\nui.drag_float(label, value, speed=1.0) -&gt; float\nui.drag_float2(label, v1, v2, speed=1.0) -&gt; tuple\nui.drag_float3(label, v1, v2, v3, speed=1.0) -&gt; tuple\nui.drag_int(label, value, speed=1.0) -&gt; int\nui.input_float(label, value) -&gt; float\nui.input_float2(label, v1, v2) -&gt; tuple\nui.input_float3(label, v1, v2, v3) -&gt; tuple\nui.input_float4(label, v1, v2, v3, v4) -&gt; tuple\nui.input_int(label, value) -&gt; int\nui.input_text(label, text, max_length=256) -&gt; str\nui.input_text_multiline(label, text, max_length=1024) -&gt; str\n</code></pre>"},{"location":"zh/api/#_23","title":"\u989c\u8272","text":"<pre><code>ui.color_edit3(label, r, g, b, flags=0) -&gt; tuple[float, float, float]\nui.color_edit4(label, r, g, b, a, flags=0) -&gt; tuple[float, float, float, float]\nui.color_picker3(label, r, g, b, flags=0) -&gt; tuple[float, float, float]\nui.color_picker4(label, r, g, b, a, flags=0) -&gt; tuple\n</code></pre>"},{"location":"zh/api/#_24","title":"\u9009\u62e9","text":"<pre><code>ui.combo(label, current: int, items: list[str]) -&gt; int\nui.listbox(label, current: int, items: list[str], height_items=-1) -&gt; int\nui.tree_node(label: str) -&gt; bool\nui.tree_pop() -&gt; None\nui.collapsing_header(label: str) -&gt; bool\nui.selectable(label: str, selected: bool = False) -&gt; bool\n</code></pre>"},{"location":"zh/api/#_25","title":"\u6807\u7b7e\u9875","text":"<pre><code>ui.begin_tab_bar(id: str) -&gt; bool\nui.end_tab_bar() -&gt; None\nui.begin_tab_item(label: str) -&gt; bool\nui.end_tab_item() -&gt; None\n</code></pre>"},{"location":"zh/api/#_26","title":"\u663e\u793a","text":"<pre><code>ui.progress_bar(fraction, sx=-1.0, sy=0.0, overlay=\"\")\nui.image(texture_id: int, width, height, uv0x=0, uv0y=0, uv1x=1, uv1y=1)\nui.image_button(id: str, texture_id: int, width, height) -&gt; bool\nui.plot_lines(label, values: list[float], offset=0, overlay=\"\", ...)\nui.plot_histogram(label, values: list[float], offset=0, overlay=\"\", ...)\n</code></pre>"},{"location":"zh/api/#_27","title":"\u5e03\u5c40","text":"<pre><code>ui.separator()\nui.same_line(offset=0.0, spacing=-1.0)\nui.new_line()\nui.spacing()\nui.dummy(width, height)\nui.indent(width=0.0)\nui.unindent(width=0.0)\nui.begin_group()\nui.end_group()\nui.push_item_width(width)\nui.pop_item_width()\nui.columns(count=1, id=None, border=True)\nui.next_column()\n</code></pre>"},{"location":"zh/api/#_28","title":"\u8868\u683c","text":"<pre><code>ui.begin_table(id: str, columns: int, flags=0) -&gt; bool\nui.end_table()\nui.table_next_row(flags=0, min_row_height=0.0)\nui.table_next_column() -&gt; bool\nui.table_set_column_index(index: int) -&gt; bool\nui.table_setup_column(label: str, flags=0, init_width=0.0)\nui.table_headers_row()\n</code></pre>"},{"location":"zh/api/#_29","title":"\u83dc\u5355","text":"<pre><code>ui.begin_main_menu_bar() -&gt; bool\nui.end_main_menu_bar()\nui.begin_menu_bar() -&gt; bool\nui.end_menu_bar()\nui.begin_menu(label: str, enabled=True) -&gt; bool\nui.end_menu()\nui.menu_item(label: str, shortcut=\"\", selected=False, enabled=True) -&gt; bool\n</code></pre>"},{"location":"zh/api/#_30","title":"\u5f39\u51fa\u7a97\u53e3","text":"<pre><code>ui.open_popup(id: str)\nui.begin_popup(id: str) -&gt; bool\nui.begin_popup_modal(name: str, flags=0) -&gt; bool\nui.end_popup()\nui.close_current_popup()\n</code></pre>"},{"location":"zh/api/#_31","title":"\u63d0\u793a\u6846","text":"<pre><code>ui.begin_tooltip()\nui.end_tooltip()\nui.set_tooltip(text: str)\n</code></pre>"},{"location":"zh/api/#id","title":"ID \u6808","text":"<pre><code>ui.push_id_str(id: str)\nui.push_id_int(id: int)\nui.pop_id()\nui.get_id(id: str) -&gt; int\n</code></pre>"},{"location":"zh/api/#_32","title":"\u6837\u5f0f","text":"<pre><code>ui.push_style_color(idx: int, r, g, b, a)\nui.pop_style_color(count=1)\nui.push_style_var_float(idx: int, value: float)\nui.push_style_var_vec2(idx: int, x: float, y: float)\nui.pop_style_var(count=1)\nui.style_colors_dark()\nui.style_colors_light()\nui.style_colors_classic()\n</code></pre>"},{"location":"zh/api/#_33","title":"\u5149\u6807\u4e0e\u7a97\u53e3\u4fe1\u606f","text":"<pre><code>ui.get_cursor_pos() -&gt; tuple[float, float]\nui.set_cursor_pos(x, y)\nui.get_content_region_avail() -&gt; tuple[float, float]\nui.get_window_size() -&gt; tuple[float, float]\nui.get_window_pos() -&gt; tuple[float, float]\nui.set_next_window_pos(x, y, cond=0)\nui.set_next_window_size(width, height, cond=0)\n</code></pre>"},{"location":"zh/api/#_34","title":"\u505c\u9760","text":"<pre><code>ui.dock_space_over_viewport(flags=0) -&gt; int\nui.dock_space(id: int, sx=0.0, sy=0.0, flags=0) -&gt; int\nui.set_next_window_dock_id(dock_id: int, cond=0)\nui.dock_builder_add_node(node_id=0, flags=0) -&gt; int\nui.dock_builder_remove_node(node_id: int)\nui.dock_builder_set_node_size(node_id, width, height)\nui.dock_builder_set_node_pos(node_id, x, y)\nui.dock_builder_split_node(node_id, split_dir, ratio) -&gt; tuple[int, int]\nui.dock_builder_dock_window(window_name: str, node_id: int)\nui.dock_builder_finish(node_id: int)\nui.dock_builder_get_node(node_id: int) -&gt; int\n</code></pre>"},{"location":"zh/api/#_35","title":"\u7ed8\u56fe","text":"<pre><code>ui.draw_line(x1, y1, x2, y2, col=0xFFFFFFFF, thickness=1.0)\nui.draw_rect(x1, y1, x2, y2, col=0xFFFFFFFF)\nui.draw_rect_filled(x1, y1, x2, y2, col=0xFFFFFFFF)\nui.draw_circle(cx, cy, radius, col=0xFFFFFFFF)\nui.draw_circle_filled(cx, cy, radius, col=0xFFFFFFFF)\nui.draw_text(x, y, col: int, text: str)\nui.bg_draw_image(texture_id, x1, y1, x2, y2)\n</code></pre>"},{"location":"zh/api/#_36","title":"\u8f93\u5165\u72b6\u6001","text":"<pre><code>ui.is_item_hovered() -&gt; bool\nui.is_item_active() -&gt; bool\nui.is_item_clicked() -&gt; bool\nui.is_item_focused() -&gt; bool\nui.is_item_edited() -&gt; bool\nui.is_item_deactivated_after_edit() -&gt; bool\nui.get_mouse_pos() -&gt; tuple[float, float]\nui.is_mouse_clicked(button: int) -&gt; bool\nui.is_mouse_double_clicked(button: int) -&gt; bool\nui.is_mouse_dragging(button: int, lock_threshold=-1.0) -&gt; bool\nui.get_mouse_drag_delta(button=0, lock_threshold=-1.0) -&gt; tuple[float, float]\nui.is_key_pressed(key: int) -&gt; bool\nui.is_key_down(key: int) -&gt; bool\n</code></pre>"},{"location":"zh/api/#_37","title":"\u5de5\u5177\u51fd\u6570","text":"<pre><code>ui.get_io_framerate() -&gt; float\nui.get_io_delta_time() -&gt; float\nui.get_time() -&gt; float\nui.get_frame_count() -&gt; int\nui.get_display_size() -&gt; tuple[float, float]\nui.col32(r: int, g: int, b: int, a: int = 255) -&gt; int\nui.show_demo_window()\nui.show_metrics_window()\n</code></pre>"},{"location":"zh/api/#_38","title":"\u5185\u90e8\u8f85\u52a9\u51fd\u6570","text":""},{"location":"zh/api/#vultorch_normalize_tensor","title":"<code>vultorch._normalize_tensor()</code>","text":"<pre><code>def _normalize_tensor(tensor) -&gt; tuple[Tensor, int, int, int]\n</code></pre> <p>\u89c4\u8303\u5316\u5f20\u91cf\u7684 dtype \u548c\u5f62\u72b6\u4ee5\u7528\u4e8e\u663e\u793a\u3002\u8fd4\u56de <code>(tensor, height, width, channels)</code>\u3002</p> <ul> <li><code>uint8</code> \u2192 <code>float32</code>\uff08\u00f7 255\uff09\uff0c<code>float16</code> \u2192 <code>float32</code>\u3002</li> <li>\u63a5\u53d7 2D <code>(H, W)</code> \u548c 3D <code>(H, W, C)</code>\uff0cC \u2208 {1, 3, 4}\u3002</li> <li>\u4e0d\u652f\u6301\u7684 dtype\u3001\u5f62\u72b6\u6216\u901a\u9053\u6570\u4f1a\u629b\u51fa <code>ValueError</code>\u3002</li> </ul>"}]}