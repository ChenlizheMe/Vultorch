{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Vultorch Tutorial","text":"<p>A step-by-step guide through Vultorch, one example at a time. Each chapter maps to a runnable script in the <code>examples/</code> folder.</p> Chapter Topic Key concepts 01 \u2014 Hello Tensor Minimal display View, Panel, Canvas, bind, run 02 \u2014 Multi-Panel Multiple panels &amp; canvases Layout, side, multi-canvas <p>More chapters coming soon.</p>"},{"location":"01_hello_tensor/","title":"01 \u2014 Hello Tensor","text":"<p>Example file: <code>examples/01_hello_tensor.py</code></p> <p>The simplest way to use Vultorch: create a window, add a panel, put a canvas on it, bind a CUDA tensor, and run.</p>"},{"location":"01_hello_tensor/#core-hierarchy","title":"Core hierarchy","text":"<pre><code>View          (top-level window)\n \u2514\u2500\u2500 Panel    (dockable ImGui sub-window)\n      \u2514\u2500\u2500 Canvas   (GPU image slot for a tensor)\n           \u2514\u2500\u2500 bind(tensor)  \u2192  auto-rendered every frame\n</code></pre> <p>That's the entire mental model.</p>"},{"location":"01_hello_tensor/#full-code","title":"Full code","text":"<pre><code>import torch\nimport vultorch\n\n# -- 1. Prepare data -------------------------------------------------------\n# A 256\u00d7256 RGB gradient.  Any (H, W, C) float32 CUDA tensor will work.\nH, W = 256, 256\nx = torch.linspace(0, 1, W, device=\"cuda\")            # horizontal ramp\ny = torch.linspace(0, 1, H, device=\"cuda\")            # vertical ramp\nt = torch.stack([\n    x.unsqueeze(0).expand(H, W),                       # R channel: left\u2192right\n    y.unsqueeze(1).expand(H, W),                       # G channel: top\u2192bottom\n    torch.full((H, W), 0.3, device=\"cuda\"),            # B channel: constant\n], dim=-1)                                             # shape: (256, 256, 3)\n\n# -- 2. Create View \u2192 Panel \u2192 Canvas \u2192 bind tensor -------------------------\nview   = vultorch.View(\"01 - Hello Tensor\", 512, 512)  # open a 512\u00d7512 window\npanel  = view.panel(\"Viewer\")                          # add one panel\ncanvas = panel.canvas(\"gradient\")                      # add a canvas to it\ncanvas.bind(t)                                         # bind the tensor\n\n# The four lines above can also be written as a one-liner:\n# view.panel(\"Viewer\").canvas(\"gradient\").bind(t)\n\n# -- 3. Run -----------------------------------------------------------------\n# run() blocks until the user closes the window.\n# The canvas auto-fills the panel and re-uploads from the bound tensor\n# every frame.\nview.run()\n</code></pre>"},{"location":"01_hello_tensor/#step-by-step-breakdown","title":"Step-by-step breakdown","text":"<ol> <li> <p>Prepare the data \u2014 any <code>(H, W)</code>, <code>(H, W, 1)</code>, <code>(H, W, 3)</code>, or <code>(H, W, 4)</code>    float32 / float16 / uint8 tensor on CUDA will work.  Vultorch handles RGBA    expansion internally.</p> </li> <li> <p>Build the object tree \u2014 <code>View</code> creates the OS window, <code>panel()</code> adds a    dockable ImGui window, <code>canvas()</code> adds a GPU image slot inside that panel,    and <code>bind()</code> connects the tensor.</p> </li> <li> <p>Run \u2014 <code>view.run()</code> enters a blocking event loop.  Every frame, the canvas    re-uploads the bound tensor and renders it.  The canvas auto-fills the panel    area by default (<code>fit=True</code>).</p> </li> </ol> <p>Tip</p> <p>The four setup lines can be collapsed into a single chain: <code>view.panel(\"Viewer\").canvas(\"gradient\").bind(t)</code></p>"},{"location":"02_multi_panel/","title":"02 \u2014 Multi-Panel","text":"<p>Example file: <code>examples/02_imgui_controls.py</code></p> <p>A single View can host any number of Panels.  Each Panel is an independent dockable window that can be dragged, resized, and rearranged by the user. This chapter shows two layout patterns:</p> <ul> <li>One canvas per panel \u2014 three panels stacked vertically, each showing a different tensor.</li> <li>Multiple canvases in one panel \u2014 a single panel with three canvases that automatically divide the space equally.</li> </ul>"},{"location":"02_multi_panel/#layout-diagram","title":"Layout diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Red (panel)             \u2502                       \u2502\n\u2502    canvas: red_img       \u2502  Combined (panel)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                       \u2502\n\u2502  Green (panel)           \u2502    canvas: c_red      \u2502\n\u2502    canvas: green_img     \u2502    canvas: c_green    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524    canvas: c_blue     \u2502\n\u2502  Blue (panel)            \u2502                       \u2502\n\u2502    canvas: blue_img      \u2502                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"02_multi_panel/#full-code","title":"Full code","text":"<pre><code>import torch\nimport vultorch\n\n# -- 1. Prepare three tensors ----------------------------------------------\nH, W = 128, 128\ndevice = \"cuda\"\n\n# Red horizontal gradient\nx = torch.linspace(0, 1, W, device=device)\nred = torch.zeros(H, W, 3, device=device)\nred[:, :, 0] = x.unsqueeze(0).expand(H, W)\n\n# Green vertical gradient\ny = torch.linspace(0, 1, H, device=device)\ngreen = torch.zeros(H, W, 3, device=device)\ngreen[:, :, 1] = y.unsqueeze(1).expand(H, W)\n\n# Blue checkerboard\nblue = torch.zeros(H, W, 3, device=device)\ncx = (torch.arange(W, device=device) // 32) % 2\ncy = (torch.arange(H, device=device) // 32) % 2\nblue[:, :, 2] = (cx.unsqueeze(0) ^ cy.unsqueeze(1)).float()\n\n# -- 2. Create View ---------------------------------------------------------\nview = vultorch.View(\"02 - Multi-Panel\", 1200, 600)\n\n# -- 3. Left side: 3 panels, each with one canvas --------------------------\npanel_r = view.panel(\"Red\")\npanel_g = view.panel(\"Green\")\npanel_b = view.panel(\"Blue\")\n\npanel_r.canvas(\"red_img\").bind(red)\npanel_g.canvas(\"green_img\").bind(green)\npanel_b.canvas(\"blue_img\").bind(blue)\n\n# -- 4. Right side: 1 panel with 3 canvases --------------------------------\ncombined = view.panel(\"Combined\", side=\"right\", width=0.5)\ncombined.canvas(\"c_red\").bind(red)\ncombined.canvas(\"c_green\").bind(green)\ncombined.canvas(\"c_blue\").bind(blue)\n\n# -- 5. Run -----------------------------------------------------------------\nview.run()\n</code></pre>"},{"location":"02_multi_panel/#key-points","title":"Key points","text":"<ol> <li> <p>Automatic layout \u2014 panels without a <code>side=</code> argument are stacked    vertically in the main area.  Use <code>side=\"left\"</code> or <code>side=\"right\"</code> to dock a    panel to a specific side, with <code>width</code> setting the ratio (e.g. <code>0.5</code> = 50%).</p> </li> <li> <p>One canvas per panel vs. many \u2014 each <code>panel.canvas()</code> call creates a new    canvas inside that panel.  When there are multiple canvases with <code>fit=True</code>    (the default), they automatically share the vertical space equally.</p> </li> <li> <p>No callback needed \u2014 for static data, just <code>bind()</code> and <code>run()</code>.  The    <code>@view.on_frame</code> decorator is only required when you need per-frame logic    (upcoming in later chapters).</p> </li> <li> <p>User can rearrange \u2014 all panels are dockable.  Users can drag title bars    to reorder panels, detach them as floating windows, or resize borders.</p> </li> </ol> <p>Note</p> <p>The same tensor can be bound to multiple canvases simultaneously. In this example, <code>red</code>, <code>green</code>, and <code>blue</code> each appear in both the left panels and the right combined panel.</p>"},{"location":"zh/","title":"Vultorch \u6559\u7a0b","text":"<p>\u9010\u6b65\u5b66\u4e60 Vultorch\uff0c\u6bcf\u4e2a\u7ae0\u8282\u5bf9\u5e94 <code>examples/</code> \u76ee\u5f55\u4e2d\u7684\u4e00\u4e2a\u53ef\u8fd0\u884c\u811a\u672c\u3002</p> \u7ae0\u8282 \u4e3b\u9898 \u6838\u5fc3\u6982\u5ff5 01 \u2014 Hello Tensor \u6700\u5c0f\u793a\u4f8b View, Panel, Canvas, bind, run 02 \u2014 \u591a\u9762\u677f \u591a\u9762\u677f\u4e0e\u591a\u753b\u5e03 \u5e03\u5c40, side, \u591a\u753b\u5e03 <p>\u66f4\u591a\u7ae0\u8282\u5373\u5c06\u63a8\u51fa\u3002</p>"},{"location":"zh/01_hello_tensor/","title":"01 \u2014 Hello Tensor","text":"<p>\u793a\u4f8b\u6587\u4ef6\uff1a <code>examples/01_hello_tensor.py</code></p> <p>Vultorch \u7684\u6700\u7b80\u7528\u6cd5\uff1a\u521b\u5efa\u7a97\u53e3\u3001\u6dfb\u52a0\u9762\u677f\u3001\u653e\u4e00\u4e2a\u753b\u5e03\u3001\u7ed1\u5b9a CUDA \u5f20\u91cf\u3001\u8fd0\u884c\u3002</p>"},{"location":"zh/01_hello_tensor/#_1","title":"\u6838\u5fc3\u5c42\u7ea7","text":"<pre><code>View          \uff08\u9876\u5c42\u7a97\u53e3\uff09\n \u2514\u2500\u2500 Panel    \uff08\u53ef\u505c\u9760\u7684 ImGui \u5b50\u7a97\u53e3\uff09\n      \u2514\u2500\u2500 Canvas   \uff08\u7528\u4e8e\u663e\u793a tensor \u7684 GPU \u56fe\u50cf\u69fd\u4f4d\uff09\n           \u2514\u2500\u2500 bind(tensor)  \u2192  \u6bcf\u5e27\u81ea\u52a8\u6e32\u67d3\n</code></pre> <p>\u8fd9\u5c31\u662f Vultorch \u7684\u5168\u90e8\u5fc3\u667a\u6a21\u578b\u3002</p>"},{"location":"zh/01_hello_tensor/#_2","title":"\u5b8c\u6574\u4ee3\u7801","text":"<pre><code>import torch\nimport vultorch\n\n# -- 1. \u51c6\u5907\u6570\u636e -----------------------------------------------------------\n# \u4e00\u5f20 256\u00d7256 \u7684 RGB \u6e10\u53d8\u8272\u3002\u4efb\u4f55 (H, W, C) float32 CUDA tensor \u5747\u53ef\u3002\nH, W = 256, 256\nx = torch.linspace(0, 1, W, device=\"cuda\")            # \u6c34\u5e73\u6e10\u53d8\ny = torch.linspace(0, 1, H, device=\"cuda\")            # \u5782\u76f4\u6e10\u53d8\nt = torch.stack([\n    x.unsqueeze(0).expand(H, W),                       # R \u901a\u9053\uff1a\u5de6\u2192\u53f3\n    y.unsqueeze(1).expand(H, W),                       # G \u901a\u9053\uff1a\u4e0a\u2192\u4e0b\n    torch.full((H, W), 0.3, device=\"cuda\"),            # B \u901a\u9053\uff1a\u5e38\u91cf\n], dim=-1)                                             # shape: (256, 256, 3)\n\n# -- 2. \u521b\u5efa View \u2192 Panel \u2192 Canvas \u2192 \u7ed1\u5b9a tensor --------------------------\nview   = vultorch.View(\"01 - Hello Tensor\", 512, 512)  # \u521b\u5efa 512\u00d7512 \u7a97\u53e3\npanel  = view.panel(\"Viewer\")                          # \u6dfb\u52a0\u4e00\u4e2a\u9762\u677f\ncanvas = panel.canvas(\"gradient\")                      # \u9762\u677f\u4e0a\u6dfb\u52a0\u753b\u5e03\ncanvas.bind(t)                                         # \u628a tensor \u7ed1\u5b9a\u5230\u753b\u5e03\n\n# \u4e0a\u9762\u56db\u884c\u4e5f\u53ef\u4ee5\u94fe\u5f0f\u5199\u6210\u4e00\u884c\uff1a\n# view.panel(\"Viewer\").canvas(\"gradient\").bind(t)\n\n# -- 3. \u8fd0\u884c ---------------------------------------------------------------\n# run() \u4f1a\u963b\u585e\uff0c\u76f4\u5230\u7528\u6237\u5173\u95ed\u7a97\u53e3\u3002\n# \u753b\u5e03\u4f1a\u81ea\u52a8\u94fa\u6ee1\u9762\u677f\u7a7a\u95f4\uff0c\u6bcf\u5e27\u4ece\u7ed1\u5b9a\u7684 tensor \u8bfb\u53d6\u6570\u636e\u5e76\u6e32\u67d3\u3002\nview.run()\n</code></pre>"},{"location":"zh/01_hello_tensor/#_3","title":"\u9010\u6b65\u89e3\u6790","text":"<ol> <li> <p>\u51c6\u5907\u6570\u636e \u2014 \u4efb\u4f55 <code>(H, W)</code>\u3001<code>(H, W, 1)</code>\u3001<code>(H, W, 3)</code> \u6216 <code>(H, W, 4)</code>\uff0c    float32 / float16 / uint8 \u7684 CUDA tensor \u90fd\u53ef\u4ee5\uff0cVultorch \u4f1a\u81ea\u52a8\u5904\u7406    RGBA \u901a\u9053\u6269\u5c55\u3002</p> </li> <li> <p>\u6784\u5efa\u5bf9\u8c61\u5c42\u7ea7 \u2014 <code>View</code> \u521b\u5efa\u64cd\u4f5c\u7cfb\u7edf\u7a97\u53e3\uff0c<code>panel()</code> \u6dfb\u52a0\u53ef\u505c\u9760\u7684    ImGui \u5b50\u7a97\u53e3\uff0c<code>canvas()</code> \u5728\u9762\u677f\u5185\u6dfb\u52a0 GPU \u56fe\u50cf\u69fd\u4f4d\uff0c<code>bind()</code> \u5c06    tensor \u8fde\u63a5\u4e0a\u53bb\u3002</p> </li> <li> <p>\u8fd0\u884c \u2014 <code>view.run()</code> \u8fdb\u5165\u963b\u585e\u4e8b\u4ef6\u5faa\u73af\u3002\u6bcf\u5e27\u753b\u5e03\u81ea\u52a8\u91cd\u65b0\u4e0a\u4f20\u7ed1\u5b9a\u7684    tensor \u5e76\u6e32\u67d3\uff0c\u9ed8\u8ba4\u94fa\u6ee1\u9762\u677f\u533a\u57df\uff08<code>fit=True</code>\uff09\u3002</p> </li> </ol> <p>\u63d0\u793a</p> <p>\u4e0a\u9762\u56db\u884c\u521d\u59cb\u5316\u53ef\u4ee5\u94fe\u5f0f\u4e00\u884c\u5199\u5b8c\uff1a <code>view.panel(\"Viewer\").canvas(\"gradient\").bind(t)</code></p>"},{"location":"zh/02_multi_panel/","title":"02 \u2014 \u591a\u9762\u677f","text":"<p>\u793a\u4f8b\u6587\u4ef6\uff1a <code>examples/02_imgui_controls.py</code></p> <p>\u4e00\u4e2a View \u53ef\u4ee5\u62e5\u6709\u4efb\u610f\u591a\u4e2a Panel\u3002\u6bcf\u4e2a Panel \u90fd\u662f\u72ec\u7acb\u7684\u53ef\u505c\u9760\u7a97\u53e3\uff0c \u7528\u6237\u53ef\u4ee5\u62d6\u62fd\u3001\u7f29\u653e\u3001\u91cd\u65b0\u6392\u5217\u3002\u672c\u7ae0\u5c55\u793a\u4e24\u79cd\u5e03\u5c40\u6a21\u5f0f\uff1a</p> <ul> <li>\u6bcf\u4e2a\u9762\u677f\u4e00\u4e2a\u753b\u5e03 \u2014 \u4e09\u4e2a\u9762\u677f\u5782\u76f4\u5806\u53e0\uff0c\u5404\u663e\u793a\u4e0d\u540c\u7684 tensor\u3002</li> <li>\u4e00\u4e2a\u9762\u677f\u591a\u4e2a\u753b\u5e03 \u2014 \u5355\u4e2a\u9762\u677f\u5185\u653e\u4e09\u4e2a\u753b\u5e03\uff0c\u81ea\u52a8\u5747\u5206\u7a7a\u95f4\u3002</li> </ul>"},{"location":"zh/02_multi_panel/#_1","title":"\u5e03\u5c40\u56fe\u793a","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Red\uff08\u9762\u677f\uff09             \u2502                       \u2502\n\u2502    canvas: red_img       \u2502  Combined\uff08\u9762\u677f\uff09     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                       \u2502\n\u2502  Green\uff08\u9762\u677f\uff09           \u2502    canvas: c_red      \u2502\n\u2502    canvas: green_img     \u2502    canvas: c_green    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524    canvas: c_blue     \u2502\n\u2502  Blue\uff08\u9762\u677f\uff09            \u2502                       \u2502\n\u2502    canvas: blue_img      \u2502                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"zh/02_multi_panel/#_2","title":"\u5b8c\u6574\u4ee3\u7801","text":"<pre><code>import torch\nimport vultorch\n\n# -- 1. \u51c6\u5907\u4e09\u4efd tensor ----------------------------------------------------\nH, W = 128, 128\ndevice = \"cuda\"\n\n# \u7ea2\u8272\u6c34\u5e73\u6e10\u53d8\nx = torch.linspace(0, 1, W, device=device)\nred = torch.zeros(H, W, 3, device=device)\nred[:, :, 0] = x.unsqueeze(0).expand(H, W)\n\n# \u7eff\u8272\u5782\u76f4\u6e10\u53d8\ny = torch.linspace(0, 1, H, device=device)\ngreen = torch.zeros(H, W, 3, device=device)\ngreen[:, :, 1] = y.unsqueeze(1).expand(H, W)\n\n# \u84dd\u8272\u68cb\u76d8\u683c\nblue = torch.zeros(H, W, 3, device=device)\ncx = (torch.arange(W, device=device) // 32) % 2\ncy = (torch.arange(H, device=device) // 32) % 2\nblue[:, :, 2] = (cx.unsqueeze(0) ^ cy.unsqueeze(1)).float()\n\n# -- 2. \u521b\u5efa View ----------------------------------------------------------\nview = vultorch.View(\"02 - Multi-Panel\", 1200, 600)\n\n# -- 3. \u5de6\u4fa7\uff1a3 \u4e2a\u9762\u677f\uff0c\u5404\u81ea\u4e00\u4e2a\u753b\u5e03 --------------------------------------\npanel_r = view.panel(\"Red\")\npanel_g = view.panel(\"Green\")\npanel_b = view.panel(\"Blue\")\n\npanel_r.canvas(\"red_img\").bind(red)\npanel_g.canvas(\"green_img\").bind(green)\npanel_b.canvas(\"blue_img\").bind(blue)\n\n# -- 4. \u53f3\u4fa7\uff1a1 \u4e2a\u9762\u677f\uff0c\u5185\u542b 3 \u4e2a\u753b\u5e03 ------------------------------------\ncombined = view.panel(\"Combined\", side=\"right\", width=0.5)\ncombined.canvas(\"c_red\").bind(red)\ncombined.canvas(\"c_green\").bind(green)\ncombined.canvas(\"c_blue\").bind(blue)\n\n# -- 5. \u8fd0\u884c ---------------------------------------------------------------\nview.run()\n</code></pre>"},{"location":"zh/02_multi_panel/#_3","title":"\u91cd\u70b9\u89e3\u6790","text":"<ol> <li> <p>\u81ea\u52a8\u5e03\u5c40 \u2014 \u4e0d\u5e26 <code>side=</code> \u53c2\u6570\u7684\u9762\u677f\u4f1a\u5728\u4e3b\u533a\u57df\u5782\u76f4\u5806\u53e0\u3002    \u4f7f\u7528 <code>side=\"left\"</code> \u6216 <code>side=\"right\"</code> \u53ef\u5c06\u9762\u677f\u505c\u9760\u5230\u6307\u5b9a\u4fa7\uff0c    \u901a\u8fc7 <code>width</code> \u6307\u5b9a\u5bbd\u5ea6\u6bd4\u4f8b\uff08\u5982 <code>0.5</code> = 50%\uff09\u3002</p> </li> <li> <p>\u5355\u753b\u5e03 vs. \u591a\u753b\u5e03 \u2014 \u6bcf\u6b21\u8c03\u7528 <code>panel.canvas()</code> \u90fd\u4f1a\u5728\u8be5\u9762\u677f\u5185\u521b\u5efa\u65b0\u7684\u753b\u5e03\u3002    \u5f53\u591a\u4e2a\u753b\u5e03\u7684 <code>fit=True</code>\uff08\u9ed8\u8ba4\u503c\uff09\u65f6\uff0c\u5b83\u4eec\u4f1a\u81ea\u52a8\u5747\u5206\u9762\u677f\u7684\u5782\u76f4\u7a7a\u95f4\u3002</p> </li> <li> <p>\u65e0\u9700\u56de\u8c03 \u2014 \u5bf9\u4e8e\u9759\u6001\u6570\u636e\uff0c\u53ea\u9700 <code>bind()</code> \u52a0 <code>run()</code>\u3002    <code>@view.on_frame</code> \u88c5\u9970\u5668\u4ec5\u5728\u9700\u8981\u9010\u5e27\u66f4\u65b0\u903b\u8f91\u65f6\u4f7f\u7528\uff08\u540e\u7eed\u7ae0\u8282\u4f1a\u8bb2\u5230\uff09\u3002</p> </li> <li> <p>\u7528\u6237\u53ef\u4ee5\u91cd\u6392 \u2014 \u6240\u6709\u9762\u677f\u90fd\u652f\u6301\u505c\u9760\u3002\u7528\u6237\u53ef\u4ee5\u62d6\u62fd\u6807\u9898\u680f\u91cd\u65b0\u6392\u5217\u3001    \u62c9\u51fa\u4e3a\u6d6e\u52a8\u7a97\u53e3\uff0c\u6216\u62d6\u62fd\u8fb9\u6846\u8c03\u6574\u5927\u5c0f\u3002</p> </li> </ol> <p>\u8bf4\u660e</p> <p>\u540c\u4e00\u4e2a tensor \u53ef\u4ee5\u540c\u65f6\u7ed1\u5b9a\u5230\u591a\u4e2a\u753b\u5e03\u3002 \u672c\u793a\u4f8b\u4e2d <code>red</code>\u3001<code>green</code>\u3001<code>blue</code> \u5404\u81ea\u540c\u65f6\u51fa\u73b0\u5728 \u5de6\u4fa7\u9762\u677f\u548c\u53f3\u4fa7\u7ec4\u5408\u9762\u677f\u4e2d\u3002</p>"}]}